{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demand Estimation: Problem Set 2\n",
    "\n",
    "Moonju Cho, Max Schnidman, Yen Ling Tan, Yang Yu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1: Deriving market shares as a function of $\\delta$ and inverting to get $\\delta$ as a function of market shares\n",
    "\n",
    "Consumers have the following utility function:\n",
    "\\begin{align}\n",
    "u_{ijt} &= \\delta_{jt} + \\epsilon_{ijt}\\\\\n",
    "\\delta_{jt} &= \\beta x_{jt} -\\alpha p_{jt} +\\xi_{jt}\n",
    "\\end{align}\n",
    "\n",
    "where $x_{jt}$ is a vector of product characteristics, $p_{jt}$ is the price of product $j$ at time $t$, and $\\xi_{jt}$ is a vector of unobserved characteristics. The $\\epsilon_{ijt}$ are i.i.d. extreme value type I.\n",
    "\n",
    "By i.i.d. extreme value type I, we have\n",
    "\\begin{align}\n",
    "s_{jt}=\\begin{cases}\n",
    "\\begin{array}{cc}\n",
    "\\frac{\\exp\\left(\\delta_{jt}\\right)}{1+\\sum_{k=1}^{J_{t}}\\exp\\left(\\delta_{kt}\\right)} & j\\geq 1\\\\\n",
    "\\frac{1}{1+\\sum_{k=1}^{J_{t}}\\exp\\left(\\delta_{kt}\\right)} & j=0\n",
    "\\end{array}\\end{cases}\n",
    "\\end{align}\n",
    "\n",
    "Taking logs and subtracting $s_{0t}$ from $s_{jt}$, we have\n",
    "\\begin{align}\n",
    "\\ln s_{jt}-\\ln s_{0t}=\\delta_{jt}=x_{jt}\\beta-\\alpha p_{jt}+\\xi_{jt}\n",
    "\\end{align}\n",
    "\n",
    "$s_{jt}$ comes from the data and is equal to $\\frac{q_{jt}}{M_t}$, making the share of the outside good $s_{0t}=1-\\sum_{j=1}^{J_t}s_{jt}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2: \n",
    "\n",
    "Under pooling, We call product $j$ in year $t$ product $l(j,t)$, so that product $l(j,t)$ is different than product $l(j,t+1)$.\n",
    "\n",
    "Under pooling, our utility function would be:\n",
    "\n",
    "\\begin{align}\n",
    "u_{il} &= \\delta_{l} + \\epsilon_{il}\\\\\n",
    "\\delta_{l} &= \\beta x_{l} -\\alpha p_{l} +\\xi_{l}\n",
    "\\end{align}\n",
    "\n",
    "We still have\n",
    "\\begin{align}\n",
    "s_{l}=\\begin{cases}\n",
    "\\begin{array}{cc}\n",
    "\\frac{\\exp\\left(\\delta_{l}\\right)}{1+\\sum_{k=1}^{L}\\exp\\left(\\delta_{k}\\right)} & l\\geq 1\\\\\n",
    "\\frac{1}{1+\\sum_{k=1}^{L}\\exp\\left(\\delta_{k}\\right)} & l=0\n",
    "\\end{array}\\end{cases}\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "By the same logic as in Q1, \n",
    "\\begin{align}\n",
    "\\ln s_{l}-\\ln s_{0}=\\delta_{l}=x_{l}\\beta-\\alpha p_{l}+\\xi_{l}\n",
    "\\end{align}\n",
    "\n",
    "$s_{l}$ comes from data and is euqal to $\\frac{q_{l}}{M}$, making the share of the outside good $s_{0}=1-\\sum_{l=1}^{L}s_{l}$\n",
    "\n",
    "The key difference is that the outside good share becomes lower under pooling if the total market size does not increase. This occurs because consumers can now substitute both\n",
    "across products and across time (i.e., a consumer can choose to purchase the same car in 1990 or 1991, and these are separate products in the data.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3: Estimating the demand system under logit assumptions\n",
    "\n",
    "First, we import the necessary packages and data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.sandbox.regression.gmm as gmm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Car_ID</th>\n",
       "      <th>Year</th>\n",
       "      <th>Firm_ID</th>\n",
       "      <th>Price</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Weight</th>\n",
       "      <th>HP</th>\n",
       "      <th>AC</th>\n",
       "      <th>Nests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53</td>\n",
       "      <td>1990</td>\n",
       "      <td>6</td>\n",
       "      <td>18820</td>\n",
       "      <td>32410</td>\n",
       "      <td>2919</td>\n",
       "      <td>114</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105</td>\n",
       "      <td>1990</td>\n",
       "      <td>18</td>\n",
       "      <td>9456</td>\n",
       "      <td>124135</td>\n",
       "      <td>2759</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71</td>\n",
       "      <td>1990</td>\n",
       "      <td>5</td>\n",
       "      <td>13071</td>\n",
       "      <td>1276</td>\n",
       "      <td>2455</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120</td>\n",
       "      <td>1990</td>\n",
       "      <td>5</td>\n",
       "      <td>11499</td>\n",
       "      <td>44906</td>\n",
       "      <td>2620</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>128</td>\n",
       "      <td>1990</td>\n",
       "      <td>16</td>\n",
       "      <td>6851</td>\n",
       "      <td>39602</td>\n",
       "      <td>2194</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Car_ID  Year  Firm_ID  Price  Quantity  Weight   HP  AC  Nests\n",
       "0      53  1990        6  18820     32410    2919  114   1      2\n",
       "1     105  1990       18   9456    124135    2759   88   0      1\n",
       "2      71  1990        5  13071      1276    2455   97   0      2\n",
       "3     120  1990        5  11499     44906    2620  130   0      2\n",
       "4     128  1990       16   6851     39602    2194   81   0      1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in data\n",
    "# parent_dir = os.path.dirname(os.getcwd())\n",
    "# CarData = pd.read_csv(parent_dir + '\\\\data\\\\data_ps2_3nests.txt', sep='\\t', header=None)\n",
    "CarData = pd.read_csv(\"C:\\\\Users\\\\chv7bg\\\\Documents\\\\coursework\\\\empirical-io\\\\Mortimer HW\\\\data\\\\ps2_data_3nests.txt\", sep='\\t', header=None)\n",
    "#name columns\n",
    "CarData.columns = ['Car_ID', 'Year', 'Firm_ID', 'Price', 'Quantity', 'Weight', 'HP', 'AC', 'Nests']\n",
    "#display data\n",
    "CarData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we define the market size for each year and use it to generate market shares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 100_000_000 #set total market size\n",
    "CarData['Market_Share'] = CarData['Quantity'] / M #construct market share as the ratio of sales to total market size\n",
    "CarData['Outside_Share'] = 1 - (CarData['Quantity'].groupby(CarData['Year']).transform('sum') / M )#construct outside share as 1 minus the ratio of sales in a given year to total market size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the instruments for price. To compute the mean characteristics of rivals, we take the difference of the sum of all product characteristics and the characteristics of the firm's products, and divide that by the number of rivals products in the market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "CarData['Rival_Weight'] = (CarData['Weight'].groupby(CarData['Year']).transform('sum') - CarData['Weight'].groupby([CarData['Year'], CarData['Firm_ID']]).transform('sum'))/(CarData['Weight'].groupby(CarData['Year']).transform('count') - CarData['Weight'].groupby([CarData['Year'], CarData['Firm_ID']]).transform('count'))\n",
    "CarData['Rival_HP'] = (CarData['HP'].groupby(CarData['Year']).transform('sum') - CarData['HP'].groupby([CarData['Year'], CarData['Firm_ID']]).transform('sum'))/(CarData['HP'].groupby(CarData['Year']).transform('count') - CarData['HP'].groupby([CarData['Year'], CarData['Firm_ID']]).transform('count'))\n",
    "CarData['Rival_AC'] = (CarData['AC'].groupby(CarData['Year']).transform('sum') - CarData['AC'].groupby([CarData['Year'], CarData['Firm_ID']]).transform('sum'))/(CarData['AC'].groupby(CarData['Year']).transform('count') - CarData['AC'].groupby([CarData['Year'], CarData['Firm_ID']]).transform('count'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We normalize the continuous variables by dividing by their mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "CarData['Weight_Norm'] = CarData['Weight'] / CarData['Weight'].mean()\n",
    "CarData['HP_Norm'] = CarData['HP'] / CarData['HP'].mean()\n",
    "CarData['Price_Norm'] = CarData['Price'] / CarData['Price'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we construct the GMM Estimator for the logit model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the endogenous variable, exogenous variables, and instruments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Endog = np.log(CarData['Market_Share']) - np.log(CarData['Outside_Share'])\n",
    "Exog = CarData[['Price_Norm', 'Weight_Norm', 'HP_Norm', 'AC']]\n",
    "Inst = CarData[['Rival_Weight', 'Rival_HP', 'Rival_AC', 'Weight_Norm', 'HP_Norm', 'AC']]\n",
    "Exog = sm.add_constant(Exog)\n",
    "Inst = sm.add_constant(Inst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Linear IV GMM function in statsmodels, we estimate the model. This package assumes the following form for the moment conditions:\n",
    "\n",
    "\\begin{equation*} \n",
    "E[z_{it}*(y_{it}-x_{it}\\beta)]=0\n",
    "\\end{equation*}\n",
    "\n",
    "Further, because the moment condition is linear, $\\beta$ has the following closed form solution, which this function solves for:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\beta_{GMM} = (X'ZWZ'X)^{-1}X'ZWZ'y\n",
    "\\end{equation*}\n",
    "\n",
    "where $W$ is the weighting matrix, and $Z$ is the matrix of instruments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to coerce to DataFrame, shape must be (393, 7): given (393, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-366f9a2219b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mLogitModel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgmm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinearIVGMM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEndog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mInst\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#we define the logit model, estimating using a linear IV GMM estimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mLogitModelFit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogitModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#we fit the model and print the summary, setting the maximum number of iterations to 2 to implement 2-step GMM; the initial weight matrix is the identity matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mLogitModelFit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Program Files\\Anaconda3\\lib\\site-packages\\statsmodels\\sandbox\\regression\\gmm.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, start_params, maxiter, inv_weights, weights_method, wargs, has_optimal_weights, optim_method, optim_args)\u001b[0m\n\u001b[0;32m    677\u001b[0m                                            \u001b[0mwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m                                            \u001b[0moptim_method\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptim_method\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 679\u001b[1;33m                                            optim_args=optim_args)\n\u001b[0m\u001b[0;32m    680\u001b[0m             \u001b[1;31m# TODO weights returned by fititer is inv_weights - not true anymore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    681\u001b[0m             \u001b[1;31m# weights_ currently not necessary and used anymore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Program Files\\Anaconda3\\lib\\site-packages\\statsmodels\\sandbox\\regression\\gmm.py\u001b[0m in \u001b[0;36mfititer\u001b[1;34m(self, start, maxiter, start_invweights, weights_method, wargs, optim_method, optim_args)\u001b[0m\n\u001b[0;32m    919\u001b[0m                                  optim_args=optim_args)\n\u001b[0;32m    920\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 921\u001b[1;33m             \u001b[0mmoms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmomcond\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresgmm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    922\u001b[0m             \u001b[1;31m# the following is S = cov_moments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m             winv_new = self.calc_weightmatrix(moms,\n",
      "\u001b[1;32mc:\\Program Files\\Anaconda3\\lib\\site-packages\\statsmodels\\sandbox\\regression\\gmm.py\u001b[0m in \u001b[0;36mmomcond\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m   1399\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmomcond\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1400\u001b[0m         \u001b[0minstrument\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minstrument\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1401\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0minstrument\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1402\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36mf\u001b[1;34m(self, other, axis, level, fill_value)\u001b[0m\n\u001b[0;32m   1545\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdefault_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1546\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1547\u001b[1;33m         \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_align_method_FRAME\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1548\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1549\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Another DataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36m_align_method_FRAME\u001b[1;34m(left, right, axis)\u001b[0m\n\u001b[0;32m   1468\u001b[0m                                  \u001b[1;34m\"must be {req_shape}: given {given_shape}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1469\u001b[0m                                  .format(req_shape=left.shape,\n\u001b[1;32m-> 1470\u001b[1;33m                                          given_shape=right.shape))\n\u001b[0m\u001b[0;32m   1471\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1472\u001b[0m             right = left._constructor(right, index=left.index,\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to coerce to DataFrame, shape must be (393, 7): given (393, 1)"
     ]
    }
   ],
   "source": [
    "LogitModel = gmm.LinearIVGMM(Endog, Exog, Inst) #we define the logit model, estimating using a linear IV GMM estimator\n",
    "LogitModelFit = LogitModel.fit(maxiter=2).summary() #we fit the model and print the summary, setting the maximum number of iterations to 2 to implement 2-step GMM; the initial weight matrix is the identity matrix\n",
    "LogitModelFit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results generally match our intuition: higher prices reduce the choice probability, but more powerful cars with AC increase the choice probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. Computing elasticities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    393.000000\n",
       "mean      -5.102218\n",
       "std        3.622023\n",
       "min      -23.084209\n",
       "25%       -6.785984\n",
       "50%       -3.784435\n",
       "75%       -2.688700\n",
       "max       -0.944018\n",
       "Name: Elast_MNL, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CarData['Elast_MNL'] = -5.1050 * CarData['Price_Norm']*(1- CarData['Market_Share']) #we calculate the price elasticity of demand for each observation\n",
    "CarData['Elast_MNL'].describe() #we print the summary statistics of the price elasticity of demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.056766</td>\n",
       "      <td>0.015125</td>\n",
       "      <td>0.012819</td>\n",
       "      <td>0.006608</td>\n",
       "      <td>0.008651</td>\n",
       "      <td>0.010828</td>\n",
       "      <td>0.009982</td>\n",
       "      <td>0.010014</td>\n",
       "      <td>0.006414</td>\n",
       "      <td>0.006442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.013452</td>\n",
       "      <td>-3.437225</td>\n",
       "      <td>0.012819</td>\n",
       "      <td>0.006608</td>\n",
       "      <td>0.008651</td>\n",
       "      <td>0.010828</td>\n",
       "      <td>0.009982</td>\n",
       "      <td>0.010014</td>\n",
       "      <td>0.006414</td>\n",
       "      <td>0.006442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.013452</td>\n",
       "      <td>0.015125</td>\n",
       "      <td>-3.059927</td>\n",
       "      <td>0.006608</td>\n",
       "      <td>0.008651</td>\n",
       "      <td>0.010828</td>\n",
       "      <td>0.009982</td>\n",
       "      <td>0.010014</td>\n",
       "      <td>0.006414</td>\n",
       "      <td>0.006442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.013452</td>\n",
       "      <td>0.015125</td>\n",
       "      <td>0.012819</td>\n",
       "      <td>-1.808967</td>\n",
       "      <td>0.008651</td>\n",
       "      <td>0.010828</td>\n",
       "      <td>0.009982</td>\n",
       "      <td>0.010014</td>\n",
       "      <td>0.006414</td>\n",
       "      <td>0.006442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.013452</td>\n",
       "      <td>0.015125</td>\n",
       "      <td>0.012819</td>\n",
       "      <td>0.006608</td>\n",
       "      <td>-2.467249</td>\n",
       "      <td>0.010828</td>\n",
       "      <td>0.009982</td>\n",
       "      <td>0.010014</td>\n",
       "      <td>0.006414</td>\n",
       "      <td>0.006442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.013452</td>\n",
       "      <td>0.015125</td>\n",
       "      <td>0.012819</td>\n",
       "      <td>0.006608</td>\n",
       "      <td>0.008651</td>\n",
       "      <td>-3.280930</td>\n",
       "      <td>0.009982</td>\n",
       "      <td>0.010014</td>\n",
       "      <td>0.006414</td>\n",
       "      <td>0.006442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.013452</td>\n",
       "      <td>0.015125</td>\n",
       "      <td>0.012819</td>\n",
       "      <td>0.006608</td>\n",
       "      <td>0.008651</td>\n",
       "      <td>0.010828</td>\n",
       "      <td>-3.026347</td>\n",
       "      <td>0.010014</td>\n",
       "      <td>0.006414</td>\n",
       "      <td>0.006442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.013452</td>\n",
       "      <td>0.015125</td>\n",
       "      <td>0.012819</td>\n",
       "      <td>0.006608</td>\n",
       "      <td>0.008651</td>\n",
       "      <td>0.010828</td>\n",
       "      <td>0.009982</td>\n",
       "      <td>-3.186653</td>\n",
       "      <td>0.006414</td>\n",
       "      <td>0.006442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.013452</td>\n",
       "      <td>0.015125</td>\n",
       "      <td>0.012819</td>\n",
       "      <td>0.006608</td>\n",
       "      <td>0.008651</td>\n",
       "      <td>0.010828</td>\n",
       "      <td>0.009982</td>\n",
       "      <td>0.010014</td>\n",
       "      <td>-2.063580</td>\n",
       "      <td>0.006442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.013452</td>\n",
       "      <td>0.015125</td>\n",
       "      <td>0.012819</td>\n",
       "      <td>0.006608</td>\n",
       "      <td>0.008651</td>\n",
       "      <td>0.010828</td>\n",
       "      <td>0.009982</td>\n",
       "      <td>0.010014</td>\n",
       "      <td>0.006414</td>\n",
       "      <td>-2.073415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -3.056766  0.015125  0.012819  0.006608  0.008651  0.010828  0.009982   \n",
       "1  0.013452 -3.437225  0.012819  0.006608  0.008651  0.010828  0.009982   \n",
       "2  0.013452  0.015125 -3.059927  0.006608  0.008651  0.010828  0.009982   \n",
       "3  0.013452  0.015125  0.012819 -1.808967  0.008651  0.010828  0.009982   \n",
       "4  0.013452  0.015125  0.012819  0.006608 -2.467249  0.010828  0.009982   \n",
       "5  0.013452  0.015125  0.012819  0.006608  0.008651 -3.280930  0.009982   \n",
       "6  0.013452  0.015125  0.012819  0.006608  0.008651  0.010828 -3.026347   \n",
       "7  0.013452  0.015125  0.012819  0.006608  0.008651  0.010828  0.009982   \n",
       "8  0.013452  0.015125  0.012819  0.006608  0.008651  0.010828  0.009982   \n",
       "9  0.013452  0.015125  0.012819  0.006608  0.008651  0.010828  0.009982   \n",
       "\n",
       "          7         8         9  \n",
       "0  0.010014  0.006414  0.006442  \n",
       "1  0.010014  0.006414  0.006442  \n",
       "2  0.010014  0.006414  0.006442  \n",
       "3  0.010014  0.006414  0.006442  \n",
       "4  0.010014  0.006414  0.006442  \n",
       "5  0.010014  0.006414  0.006442  \n",
       "6  0.010014  0.006414  0.006442  \n",
       "7 -3.186653  0.006414  0.006442  \n",
       "8  0.010014 -2.063580  0.006442  \n",
       "9  0.010014  0.006414 -2.073415  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sort data by quantity\n",
    "CarData = CarData.sort_values(by=['Quantity'], ascending=False)\n",
    "\n",
    "#create a 10x10 matrix of zeros\n",
    "Elast_MNL = np.zeros((10,10))\n",
    "#On the diagonal, we calculate the price elasticity of demand for each observation\n",
    "for i in range(10):\n",
    "    Elast_MNL[i,i] = -5.1050 * CarData['Price_Norm'].iloc[i]*(1- CarData['Market_Share'].iloc[i])\n",
    "#On the off-diagonal, we calculate the cross-price elasticity of demand for each observation\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        if i != j:\n",
    "            Elast_MNL[i,j] = 5.1050 * CarData['Price_Norm'].iloc[j]*CarData['Market_Share'].iloc[j]\n",
    "\n",
    "#we print the matrix as a table\n",
    "pd.DataFrame(Elast_MNL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross-price elasticity is $\\alpha p_ks_k$, suggesting that the percentage increase in all other products is the same given an increase in $p_k$. It doesn't capture the possibility that the old buyers of product $k$ are more likely to switch to similar products as $k$.\n",
    "\n",
    "The own price elasticity suggests that two products have the same markup if they have the same shares, under most pricing models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nested Logit Estimation\n",
    "\n",
    "Q5. (a) In a nested logit model, consumer utility is $u_{ijt} = \\delta^*_{jt}+\\zeta_{igt}+(1-\\sigma)\\varepsilon_{ijt}$, where the group-specific and product-specific idiosyncratic taste errors ($\\zeta_{igt}$ and $\\varepsilon_{ijt}$) are distributed in such a way where the sum of them follows a Generalized Extreme Value distribution. $\\varepsilon_{ijt}$ follows a type 1 Extreme Value distribution and $\\sigma\\in [0,1]$ is a parameter that governs the taste correlation between products in the same nest. \n",
    "\n",
    "The market share of product $j$ is divided into the group-level market share and the within-group market share. Product $j$'s within-group market share is $\\mathcal{s}_{j|gt}=\\frac{\\exp(\\delta_{jt}/(1-\\sigma))}{D_{gt}}$, where $ {D}_{gt} = \\sum_{k\\in {J}_{gt}} \\exp(\\delta_{jt}/(1-\\sigma) )$, and the group-level market share is $\\mathcal{s}_{gt} = \\frac{D_{gt}^{1-\\sigma}}{\\sum_{g'} D_{g't}^{1-\\sigma}}$. The product's unconditional market share simplifies to\n",
    "\n",
    "\\begin{equation*}\n",
    " \\mathcal{s}_{jt} = \\mathcal{s}_{jt|gt}\\cdot\\mathcal{s}_{gt}=\\frac{\\exp(\\delta_{jt}/(1-\\sigma) )}{D_g^\\sigma \\sum_{g'} D_{g't}^{1-\\sigma}}.\n",
    "\\end{equation*}\n",
    "\n",
    "(b) When the mean utility level of the outside option is normalized as $0$, and its nest exclusively contains the outside option, its market share is $\\mathcal{s}_{ot}=\\frac{1}{\\sum_{g'} D_{g'}^{1-\\sigma}}$. Then,\n",
    "\n",
    "\\begin{equation*}\n",
    "\\ln s_{jt} - \\ln s_{ot} = \\delta_{jt}/(1-\\sigma) -\\sigma \\ln D_{gt}=\\delta_{jt}/(1-\\sigma) -\\frac{\\sigma}{1-\\sigma}\\ln(s_{gt}/s_{ot})\n",
    "\\end{equation*}, \n",
    "\n",
    " where the last equality follows from incorporating $\\ln D_{gt} = \\frac{\\ln(s_{gt}/s_{ot})}{1-\\sigma}$ from the group-level market share. By combining terms, we get the inversion: $\\delta_{jt}=\\ln(s_{jt}/s_{ot})-\\sigma \\mathcal{s}_{jt|gt}$.\n",
    "\n",
    "\n",
    "(c) By moving all parameters and errors on the RHS, we can get a regression equation: $\\ln(s_{jt}/s_{ot}) = x_{jt}\\beta - \\alpha p_{jt}+\\sigma \\ln s_{jt|gt} +\\xi_{jt}$.\n",
    "\n",
    "Q6. (a) The nested logit model relaxes the IIA problem in a logit model. By adding a nest-specific error term, we allow substitution patterns between products with similar characteristics to be positively correlated. The IIA problem stems from the iid additive error (iid consumer tastes), which implies that market shares and elasticities are only determined by the mean utility levels $\\delta_{j}$, with no effect from individual product characteristics or prices. For example, if we have a dataset in which an inexpensive Toyota Camry has the same market share as a luxury car like Porsche 911 Carrera, then in a logit model, they have the same cross-price elasticity with any given third car in the data. This substitution pattern that is based on existing market share is unrealistic. With nested logit, products are grouped into nests so that the IIA property holds within a nest but not across nests. In other words, if we place Toyota Camry and Honda Accord in the same nest and they have the same market share, they will have the same cross-price elasticity with any given third car in the data. If we place Toyota Camry and Porsche 911 Carrera in different nests and they have the same market share, they do not need to have the same cross-price elasticity with any given third car in the data.\n",
    "\n",
    "(b) The nested logit model has several weaknesses. First, a researcher needs to form a priori assumptions about taste correlation to group products into different nests; these assumptions can be formed without looking at the data, even though ideally we would like to let the data tell us the nests. Second, different nest structures may produce different results; the ordering of the nest structure can affect the estimates. Third, a researcher needs to be able to group the products into nests, and it may be difficult to use a nested logit model if there are no obvious nests in the product market."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7. (a) To estimate the nested logit model, we first create the necessary data and instruments. We create the products' within-nest market share, and take its log as an exogenous variable. We also generate instruments as the mean of rival within-nest product characteristics, considering products produced by the same firm within a given nest to be rivalrous. \n",
    "\n",
    "We then split the data by year to estimate three separate models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a copy of the data\n",
    "CarDataNL = CarData.copy()\n",
    "#we calculate the market share for each observation by year and nest, then take its log\n",
    "CarDataNL['Nest_Share'] = CarDataNL['Quantity']/CarDataNL['Quantity'].groupby([CarDataNL['Year'], CarDataNL['Nests']]).transform('sum')\n",
    "CarDataNL['LogNest_Share'] = np.log(CarDataNL['Nest_Share'])\n",
    "#we calculate the inside share for each observation by year, then take its log\n",
    "CarDataNL['Inside_Share'] = CarDataNL['Quantity']/CarDataNL['Quantity'].groupby(CarDataNL['Year']).transform('sum')\n",
    "CarDataNL['LogInside_Share'] = np.log(CarDataNL['Inside_Share'])\n",
    "#we construct the instruments, this time by nest\n",
    "CarDataNL['Rival_Nest_Weight'] = (CarDataNL['Weight'].groupby([CarDataNL['Year'], CarDataNL['Nests']]).transform('sum') - CarDataNL['Weight'])/(CarDataNL['Weight'].groupby([CarDataNL['Year'], CarDataNL['Nests']]).transform('count') - 1)\n",
    "CarDataNL['Rival_Nest_HP'] = (CarDataNL['HP'].groupby([CarDataNL['Year'], CarDataNL['Nests']]).transform('sum') - CarDataNL['HP'])/(CarDataNL['HP'].groupby([CarDataNL['Year'], CarDataNL['Nests']]).transform('count') - 1)\n",
    "CarDataNL['Rival_Nest_AC'] = (CarDataNL['AC'].groupby([CarDataNL['Year'], CarDataNL['Nests']]).transform('sum') - CarDataNL['AC'])/(CarDataNL['AC'].groupby([CarDataNL['Year'], CarDataNL['Nests']]).transform('count') - 1)\n",
    "#next, create three dataframes, one for each year\n",
    "CarDataNL_1990 = CarDataNL[CarDataNL['Year'] == 1990]\n",
    "CarDataNL_1991 = CarDataNL[CarDataNL['Year'] == 1991]\n",
    "CarDataNL_1992 = CarDataNL[CarDataNL['Year'] == 1992]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create endogenous and exogenous variables for each year\n",
    "Endog_1990 = np.log(CarDataNL_1990['Market_Share']) - np.log(CarDataNL_1990['Outside_Share'])\n",
    "Exog_1990 = CarDataNL_1990[['Price_Norm', 'Weight_Norm', 'HP_Norm', 'AC', 'LogNest_Share']]\n",
    "Inst_1990 = CarDataNL_1990[['Rival_Weight', 'Rival_HP', 'Rival_AC', 'Weight_Norm', 'HP_Norm', 'AC', 'Rival_Nest_Weight', 'Rival_Nest_HP', 'Rival_Nest_AC']]\n",
    "Exog_1990 = sm.add_constant(Exog_1990)\n",
    "Inst_1990 = sm.add_constant(Inst_1990)\n",
    "\n",
    "Endog_1991 = np.log(CarDataNL_1991['Market_Share']) - np.log(CarDataNL_1991['Outside_Share'])\n",
    "Exog_1991 = CarDataNL_1991[['Price_Norm', 'Weight_Norm', 'HP_Norm', 'AC', 'LogNest_Share']]\n",
    "Inst_1991 = CarDataNL_1991[['Rival_Weight', 'Rival_HP', 'Rival_AC', 'Weight_Norm', 'HP_Norm', 'AC', 'Rival_Nest_Weight', 'Rival_Nest_HP', 'Rival_Nest_AC']]\n",
    "Exog_1991 = sm.add_constant(Exog_1991)\n",
    "Inst_1991 = sm.add_constant(Inst_1991)\n",
    "\n",
    "Endog_1992 = np.log(CarDataNL_1992['Market_Share']) - np.log(CarDataNL_1992['Outside_Share'])\n",
    "Exog_1992 = CarDataNL_1992[['Price_Norm', 'Weight_Norm', 'HP_Norm', 'AC', 'LogNest_Share']]\n",
    "Inst_1992 = CarDataNL_1992[['Rival_Weight', 'Rival_HP', 'Rival_AC', 'Weight_Norm', 'HP_Norm', 'AC', 'Rival_Nest_Weight', 'Rival_Nest_HP', 'Rival_Nest_AC']]\n",
    "Exog_1992 = sm.add_constant(Exog_1992)\n",
    "Inst_1992 = sm.add_constant(Inst_1992)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We once again use the Linear IV GMM function in statsmodels to estimate the model for each year.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to coerce to DataFrame, shape must be (131, 10): given (131, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-4841cc3a315c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#use the linear IV GMM estimator to estimate the model for each year\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mLogitModel_1990\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgmm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinearIVGMM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEndog_1990\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExog_1990\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mInst_1990\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mLogitModelFit_1990\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogitModel_1990\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mLogitModelFit_1990\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Program Files\\Anaconda3\\lib\\site-packages\\statsmodels\\sandbox\\regression\\gmm.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, start_params, maxiter, inv_weights, weights_method, wargs, has_optimal_weights, optim_method, optim_args)\u001b[0m\n\u001b[0;32m    677\u001b[0m                                            \u001b[0mwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m                                            \u001b[0moptim_method\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptim_method\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 679\u001b[1;33m                                            optim_args=optim_args)\n\u001b[0m\u001b[0;32m    680\u001b[0m             \u001b[1;31m# TODO weights returned by fititer is inv_weights - not true anymore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    681\u001b[0m             \u001b[1;31m# weights_ currently not necessary and used anymore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Program Files\\Anaconda3\\lib\\site-packages\\statsmodels\\sandbox\\regression\\gmm.py\u001b[0m in \u001b[0;36mfititer\u001b[1;34m(self, start, maxiter, start_invweights, weights_method, wargs, optim_method, optim_args)\u001b[0m\n\u001b[0;32m    919\u001b[0m                                  optim_args=optim_args)\n\u001b[0;32m    920\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 921\u001b[1;33m             \u001b[0mmoms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmomcond\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresgmm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    922\u001b[0m             \u001b[1;31m# the following is S = cov_moments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m             winv_new = self.calc_weightmatrix(moms,\n",
      "\u001b[1;32mc:\\Program Files\\Anaconda3\\lib\\site-packages\\statsmodels\\sandbox\\regression\\gmm.py\u001b[0m in \u001b[0;36mmomcond\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m   1399\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmomcond\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1400\u001b[0m         \u001b[0minstrument\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minstrument\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1401\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0minstrument\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1402\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36mf\u001b[1;34m(self, other, axis, level, fill_value)\u001b[0m\n\u001b[0;32m   1545\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdefault_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1546\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1547\u001b[1;33m         \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_align_method_FRAME\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1548\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1549\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Another DataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36m_align_method_FRAME\u001b[1;34m(left, right, axis)\u001b[0m\n\u001b[0;32m   1468\u001b[0m                                  \u001b[1;34m\"must be {req_shape}: given {given_shape}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1469\u001b[0m                                  .format(req_shape=left.shape,\n\u001b[1;32m-> 1470\u001b[1;33m                                          given_shape=right.shape))\n\u001b[0m\u001b[0;32m   1471\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1472\u001b[0m             right = left._constructor(right, index=left.index,\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to coerce to DataFrame, shape must be (131, 10): given (131, 1)"
     ]
    }
   ],
   "source": [
    "#use the linear IV GMM estimator to estimate the model for each year\n",
    "LogitModel_1990 = gmm.LinearIVGMM(Endog_1990, Exog_1990, Inst_1990)\n",
    "LogitModelFit_1990 = LogitModel_1990.fit(maxiter=2).summary()\n",
    "LogitModelFit_1990"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>LinearIVGMM Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  Hansen J:          </th> <td>   12.30</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>LinearIVGMM</td>   <th>  Prob (Hansen J):   </th>  <td>0.0152</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                  <td>GMM</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 01 Nov 2023</td> <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>09:53:30</td>     <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   131</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>           <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>         <td>   -6.0966</td> <td>    0.668</td> <td>   -9.129</td> <td> 0.000</td> <td>   -7.406</td> <td>   -4.788</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Price_Norm</th>    <td>   -2.1382</td> <td>    0.583</td> <td>   -3.665</td> <td> 0.000</td> <td>   -3.282</td> <td>   -0.995</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Weight_Norm</th>   <td>    1.9695</td> <td>    0.605</td> <td>    3.257</td> <td> 0.001</td> <td>    0.784</td> <td>    3.155</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HP_Norm</th>       <td>    1.1506</td> <td>    0.860</td> <td>    1.338</td> <td> 0.181</td> <td>   -0.535</td> <td>    2.837</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AC</th>            <td>    0.3163</td> <td>    0.145</td> <td>    2.180</td> <td> 0.029</td> <td>    0.032</td> <td>    0.601</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LogNest_Share</th> <td>    0.6283</td> <td>    0.081</td> <td>    7.795</td> <td> 0.000</td> <td>    0.470</td> <td>    0.786</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  Hansen J:          } &     12.30   \\\\\n",
       "\\textbf{Model:}            &   LinearIVGMM    & \\textbf{  Prob (Hansen J):   } &   0.0152    \\\\\n",
       "\\textbf{Method:}           &       GMM        & \\textbf{                     } &             \\\\\n",
       "\\textbf{Date:}             & Wed, 01 Nov 2023 & \\textbf{                     } &             \\\\\n",
       "\\textbf{Time:}             &     09:53:30     & \\textbf{                     } &             \\\\\n",
       "\\textbf{No. Observations:} &         131      & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                        & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}          &      -6.0966  &        0.668     &    -9.129  &         0.000        &       -7.406    &       -4.788     \\\\\n",
       "\\textbf{Price\\_Norm}    &      -2.1382  &        0.583     &    -3.665  &         0.000        &       -3.282    &       -0.995     \\\\\n",
       "\\textbf{Weight\\_Norm}   &       1.9695  &        0.605     &     3.257  &         0.001        &        0.784    &        3.155     \\\\\n",
       "\\textbf{HP\\_Norm}       &       1.1506  &        0.860     &     1.338  &         0.181        &       -0.535    &        2.837     \\\\\n",
       "\\textbf{AC}             &       0.3163  &        0.145     &     2.180  &         0.029        &        0.032    &        0.601     \\\\\n",
       "\\textbf{LogNest\\_Share} &       0.6283  &        0.081     &     7.795  &         0.000        &        0.470    &        0.786     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{LinearIVGMM Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                             LinearIVGMM Results                              \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   Hansen J:                        12.30\n",
       "Model:                    LinearIVGMM   Prob (Hansen J):                0.0152\n",
       "Method:                           GMM                                         \n",
       "Date:                Wed, 01 Nov 2023                                         \n",
       "Time:                        09:53:30                                         \n",
       "No. Observations:                 131                                         \n",
       "=================================================================================\n",
       "                    coef    std err          z      P>|z|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------\n",
       "const            -6.0966      0.668     -9.129      0.000      -7.406      -4.788\n",
       "Price_Norm       -2.1382      0.583     -3.665      0.000      -3.282      -0.995\n",
       "Weight_Norm       1.9695      0.605      3.257      0.001       0.784       3.155\n",
       "HP_Norm           1.1506      0.860      1.338      0.181      -0.535       2.837\n",
       "AC                0.3163      0.145      2.180      0.029       0.032       0.601\n",
       "LogNest_Share     0.6283      0.081      7.795      0.000       0.470       0.786\n",
       "=================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogitModel_1991 = gmm.LinearIVGMM(Endog_1991, Exog_1991, Inst_1991)\n",
    "LogitModelFit_1991 = LogitModel_1991.fit(maxiter=2).summary()\n",
    "LogitModelFit_1991"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>LinearIVGMM Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  Hansen J:          </th> <td>   14.82</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>LinearIVGMM</td>   <th>  Prob (Hansen J):   </th>  <td>0.00510</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                  <td>GMM</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 01 Nov 2023</td> <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>09:53:31</td>     <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   131</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>           <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>         <td>   -6.1142</td> <td>    0.662</td> <td>   -9.234</td> <td> 0.000</td> <td>   -7.412</td> <td>   -4.816</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Price_Norm</th>    <td>   -1.9677</td> <td>    0.577</td> <td>   -3.413</td> <td> 0.001</td> <td>   -3.098</td> <td>   -0.838</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Weight_Norm</th>   <td>    2.1166</td> <td>    0.592</td> <td>    3.574</td> <td> 0.000</td> <td>    0.956</td> <td>    3.277</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HP_Norm</th>       <td>    1.2091</td> <td>    0.902</td> <td>    1.341</td> <td> 0.180</td> <td>   -0.558</td> <td>    2.976</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AC</th>            <td>    0.4307</td> <td>    0.137</td> <td>    3.154</td> <td> 0.002</td> <td>    0.163</td> <td>    0.698</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LogNest_Share</th> <td>    0.6634</td> <td>    0.081</td> <td>    8.181</td> <td> 0.000</td> <td>    0.505</td> <td>    0.822</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  Hansen J:          } &     14.82   \\\\\n",
       "\\textbf{Model:}            &   LinearIVGMM    & \\textbf{  Prob (Hansen J):   } &  0.00510    \\\\\n",
       "\\textbf{Method:}           &       GMM        & \\textbf{                     } &             \\\\\n",
       "\\textbf{Date:}             & Wed, 01 Nov 2023 & \\textbf{                     } &             \\\\\n",
       "\\textbf{Time:}             &     09:53:31     & \\textbf{                     } &             \\\\\n",
       "\\textbf{No. Observations:} &         131      & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                        & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}          &      -6.1142  &        0.662     &    -9.234  &         0.000        &       -7.412    &       -4.816     \\\\\n",
       "\\textbf{Price\\_Norm}    &      -1.9677  &        0.577     &    -3.413  &         0.001        &       -3.098    &       -0.838     \\\\\n",
       "\\textbf{Weight\\_Norm}   &       2.1166  &        0.592     &     3.574  &         0.000        &        0.956    &        3.277     \\\\\n",
       "\\textbf{HP\\_Norm}       &       1.2091  &        0.902     &     1.341  &         0.180        &       -0.558    &        2.976     \\\\\n",
       "\\textbf{AC}             &       0.4307  &        0.137     &     3.154  &         0.002        &        0.163    &        0.698     \\\\\n",
       "\\textbf{LogNest\\_Share} &       0.6634  &        0.081     &     8.181  &         0.000        &        0.505    &        0.822     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{LinearIVGMM Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                             LinearIVGMM Results                              \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   Hansen J:                        14.82\n",
       "Model:                    LinearIVGMM   Prob (Hansen J):               0.00510\n",
       "Method:                           GMM                                         \n",
       "Date:                Wed, 01 Nov 2023                                         \n",
       "Time:                        09:53:31                                         \n",
       "No. Observations:                 131                                         \n",
       "=================================================================================\n",
       "                    coef    std err          z      P>|z|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------\n",
       "const            -6.1142      0.662     -9.234      0.000      -7.412      -4.816\n",
       "Price_Norm       -1.9677      0.577     -3.413      0.001      -3.098      -0.838\n",
       "Weight_Norm       2.1166      0.592      3.574      0.000       0.956       3.277\n",
       "HP_Norm           1.2091      0.902      1.341      0.180      -0.558       2.976\n",
       "AC                0.4307      0.137      3.154      0.002       0.163       0.698\n",
       "LogNest_Share     0.6634      0.081      8.181      0.000       0.505       0.822\n",
       "=================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogitModel_1992 = gmm.LinearIVGMM(Endog_1992, Exog_1992, Inst_1992)\n",
    "LogitModelFit_1992 = LogitModel_1992.fit(maxiter=2).summary()\n",
    "LogitModelFit_1992"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To cross-validate this, we also use a nonlinear solver to estimate the model. We use the following code to estimate the model for each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TwoStepGMM(Endog,Exog,Inst): #we define a function that implements the two-step GMM estimator, taking the endogenous variable, exogenous variables, and instruments as inputs\n",
    "    #to determine the initial values for the nonlinear GMM estimator, we first run a linear 2SLS regression\n",
    "    #For the first stage, we regress each of our endogenous variables on the instruments and calculate the fitted values\n",
    "    TSLS1a = sm.OLS(Exog['Price_Norm'], Inst).fit().fittedvalues \n",
    "    TSLS1b = sm.OLS(Exog['LogNest_Share'], Inst).fit().fittedvalues\n",
    "    #we then construct a dataframe with the fitted values and the exogenous variables\n",
    "    ExogTSLS = pd.DataFrame({'const':np.ones(Exog.shape[0]), 'TSLS1a':TSLS1a, 'TSLS1b':TSLS1b, 'Weight_Norm':Exog['Weight_Norm'], 'HP_Norm':Exog['HP_Norm'], 'AC':Exog['AC']})\n",
    "    TSLS2 = sm.OLS(Endog, ExogTSLS).fit().params #we run a second stage regression of the endogenous variable on the fitted values and the exogenous variables, and save the coefficients\n",
    "    W_1 = np.identity(Inst.shape[1]) #we set the initial weight matrix to the identity matrix\n",
    "    #we define a function that calculates the objective function for the nonlinear GMM estimator\n",
    "    def Estimator(beta,W):\n",
    "        nobs = Endog.shape[0] #we calculate the number of observations based on the number of rows in the endogenous variable\n",
    "        MC = (1/nobs)*np.matmul(Inst.T, Endog - np.matmul(Exog, beta)) #we calculate the moment conditions, which as the form E[z(y-Xb)] = 0\n",
    "        Obj = np.matmul(np.matmul(MC.T,W), MC) #we calculate the GMM objective function as MC'*W*MC\n",
    "        return Obj\n",
    "    #having defined the objective function, we now implement the first stage of the nonlinear GMM estimator\n",
    "    beta_1 = sp.optimize.minimize(Estimator, x0=TSLS2, args=(W_1), method='BFGS', options={'maxiter': 1e5,'gtol': 1e-24}).x #we estimate the first-step coefficients using the BFGS algorithm, using the 2SLS coefficients as the initial values\n",
    "    Resid_1 = Endog - np.matmul(Exog, beta_1) #we calculate the residuals from the first step to construct the optimal weight matrix\n",
    "    W_2 = np.linalg.inv((1/Endog.shape[0]) * np.matmul(np.matmul(Inst.T, np.diag(Resid_1**2)), Inst)) #we calculate the optimal weight matrix\n",
    "    beta_2 = sp.optimize.minimize(Estimator, x0=beta_1, args=(W_2), method='BFGS', options={'maxiter': 1e5,'gtol': 1e-24}).x #we estimate the second-step coefficients using the BFGS algorithm, using the first-step coefficients as the initial values and the optimal weight matrix\n",
    "    Sigma = ((Endog- np.matmul(Exog,beta_2)).T @ (Endog- np.matmul(Exog,beta_2)))/(Exog.shape[0]-Exog.shape[1]) #we calculate the variance of the residuals\n",
    "    #generate variance-covariance matrix\n",
    "    VCOV = Sigma**2 * np.linalg.inv(np.dot(Exog.transpose(),Exog)) #we calculate the variance-covariance matrix\n",
    "    #generate standard errors\n",
    "    SE = np.sqrt(np.diag(VCOV)) #we calculate the standard errors\n",
    "    return TSLS2 ,beta_1, beta_2, SE #this function returns the 2SLS coefficients, the first-step coefficients, the second-step coefficients, and the standard errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having defined our two-step GMM estimator, we now estimate the model for each year, collecting the estimates, standard errors, and T-statistics in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mes7jw\\AppData\\Local\\Temp\\ipykernel_31344\\3580595035.py:19: FutureWarning: Calling a ufunc on non-aligned DataFrames (or DataFrame/Series combination). Currently, the indices are ignored and the result takes the index/columns of the first DataFrame. In the future , the DataFrames/Series will be aligned before applying the ufunc.\n",
      "Convert one of the arguments to a NumPy array (eg 'ufunc(df1, np.asarray(df2)') to keep the current behaviour, or align manually (eg 'df1, df2 = df1.align(df2)') before passing to the ufunc to obtain the future behaviour and silence this warning.\n",
      "  W_2 = np.linalg.inv((1/Endog.shape[0]) * np.matmul(np.matmul(Inst.T, np.diag(Resid_1**2)), Inst)) #we calculate the optimal weight matrix\n",
      "C:\\Users\\mes7jw\\AppData\\Local\\Temp\\ipykernel_31344\\3580595035.py:19: FutureWarning: Calling a ufunc on non-aligned DataFrames (or DataFrame/Series combination). Currently, the indices are ignored and the result takes the index/columns of the first DataFrame. In the future , the DataFrames/Series will be aligned before applying the ufunc.\n",
      "Convert one of the arguments to a NumPy array (eg 'ufunc(df1, np.asarray(df2)') to keep the current behaviour, or align manually (eg 'df1, df2 = df1.align(df2)') before passing to the ufunc to obtain the future behaviour and silence this warning.\n",
      "  W_2 = np.linalg.inv((1/Endog.shape[0]) * np.matmul(np.matmul(Inst.T, np.diag(Resid_1**2)), Inst)) #we calculate the optimal weight matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Standard Error</th>\n",
       "      <th>T Statistic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>const</th>\n",
       "      <td>-6.461531</td>\n",
       "      <td>0.889488</td>\n",
       "      <td>-7.264322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Price_Norm</th>\n",
       "      <td>-3.279167</td>\n",
       "      <td>0.294424</td>\n",
       "      <td>-11.137551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weight_Norm</th>\n",
       "      <td>2.126848</td>\n",
       "      <td>0.938240</td>\n",
       "      <td>2.266848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HP_Norm</th>\n",
       "      <td>1.586206</td>\n",
       "      <td>0.613275</td>\n",
       "      <td>2.586451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AC</th>\n",
       "      <td>0.587710</td>\n",
       "      <td>0.335139</td>\n",
       "      <td>1.753630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogNest_Share</th>\n",
       "      <td>0.538611</td>\n",
       "      <td>0.075881</td>\n",
       "      <td>7.098140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Coefficient  Standard Error  T Statistic\n",
       "const            -6.461531        0.889488    -7.264322\n",
       "Price_Norm       -3.279167        0.294424   -11.137551\n",
       "Weight_Norm       2.126848        0.938240     2.266848\n",
       "HP_Norm           1.586206        0.613275     2.586451\n",
       "AC                0.587710        0.335139     1.753630\n",
       "LogNest_Share     0.538611        0.075881     7.098140"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_1990 = TwoStepGMM(Endog_1990,Exog_1990,Inst_1990)[2]\n",
    "se_1990 = TwoStepGMM(Endog_1990,Exog_1990,Inst_1990)[3]\n",
    "T_1990 = beta_1990/se_1990 #we calculate the t-statistics as the ratio of the coefficients to the standard errors\n",
    "Res_1990 = pd.DataFrame({'Coefficient':beta_1990, 'Standard Error':se_1990, \"T Statistic\": T_1990}, index=['const', 'Price_Norm', 'Weight_Norm', 'HP_Norm', 'AC', 'LogNest_Share'])\n",
    "Res_1990"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mes7jw\\AppData\\Local\\Temp\\ipykernel_31344\\3580595035.py:19: FutureWarning: Calling a ufunc on non-aligned DataFrames (or DataFrame/Series combination). Currently, the indices are ignored and the result takes the index/columns of the first DataFrame. In the future , the DataFrames/Series will be aligned before applying the ufunc.\n",
      "Convert one of the arguments to a NumPy array (eg 'ufunc(df1, np.asarray(df2)') to keep the current behaviour, or align manually (eg 'df1, df2 = df1.align(df2)') before passing to the ufunc to obtain the future behaviour and silence this warning.\n",
      "  W_2 = np.linalg.inv((1/Endog.shape[0]) * np.matmul(np.matmul(Inst.T, np.diag(Resid_1**2)), Inst)) #we calculate the optimal weight matrix\n",
      "C:\\Users\\mes7jw\\AppData\\Local\\Temp\\ipykernel_31344\\3580595035.py:19: FutureWarning: Calling a ufunc on non-aligned DataFrames (or DataFrame/Series combination). Currently, the indices are ignored and the result takes the index/columns of the first DataFrame. In the future , the DataFrames/Series will be aligned before applying the ufunc.\n",
      "Convert one of the arguments to a NumPy array (eg 'ufunc(df1, np.asarray(df2)') to keep the current behaviour, or align manually (eg 'df1, df2 = df1.align(df2)') before passing to the ufunc to obtain the future behaviour and silence this warning.\n",
      "  W_2 = np.linalg.inv((1/Endog.shape[0]) * np.matmul(np.matmul(Inst.T, np.diag(Resid_1**2)), Inst)) #we calculate the optimal weight matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Standard Error</th>\n",
       "      <th>T Statistic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>const</th>\n",
       "      <td>-7.062775</td>\n",
       "      <td>0.698353</td>\n",
       "      <td>-10.113467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Price_Norm</th>\n",
       "      <td>-2.722358</td>\n",
       "      <td>0.227830</td>\n",
       "      <td>-11.949074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weight_Norm</th>\n",
       "      <td>2.798372</td>\n",
       "      <td>0.783250</td>\n",
       "      <td>3.572772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HP_Norm</th>\n",
       "      <td>1.583674</td>\n",
       "      <td>0.525904</td>\n",
       "      <td>3.011339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AC</th>\n",
       "      <td>0.337427</td>\n",
       "      <td>0.229078</td>\n",
       "      <td>1.472977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogNest_Share</th>\n",
       "      <td>0.570838</td>\n",
       "      <td>0.067066</td>\n",
       "      <td>8.511623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Coefficient  Standard Error  T Statistic\n",
       "const            -7.062775        0.698353   -10.113467\n",
       "Price_Norm       -2.722358        0.227830   -11.949074\n",
       "Weight_Norm       2.798372        0.783250     3.572772\n",
       "HP_Norm           1.583674        0.525904     3.011339\n",
       "AC                0.337427        0.229078     1.472977\n",
       "LogNest_Share     0.570838        0.067066     8.511623"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_1991 = TwoStepGMM(Endog_1991,Exog_1991,Inst_1991)[2]\n",
    "se_1991 = TwoStepGMM(Endog_1991,Exog_1991,Inst_1991)[3]\n",
    "T_1991 = beta_1991/se_1991\n",
    "Res_1991 = pd.DataFrame({'Coefficient':beta_1991, 'Standard Error':se_1991, \"T Statistic\": T_1991}, index=['const', 'Price_Norm', 'Weight_Norm', 'HP_Norm', 'AC', 'LogNest_Share'])\n",
    "Res_1991"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mes7jw\\AppData\\Local\\Temp\\ipykernel_31344\\3580595035.py:19: FutureWarning: Calling a ufunc on non-aligned DataFrames (or DataFrame/Series combination). Currently, the indices are ignored and the result takes the index/columns of the first DataFrame. In the future , the DataFrames/Series will be aligned before applying the ufunc.\n",
      "Convert one of the arguments to a NumPy array (eg 'ufunc(df1, np.asarray(df2)') to keep the current behaviour, or align manually (eg 'df1, df2 = df1.align(df2)') before passing to the ufunc to obtain the future behaviour and silence this warning.\n",
      "  W_2 = np.linalg.inv((1/Endog.shape[0]) * np.matmul(np.matmul(Inst.T, np.diag(Resid_1**2)), Inst)) #we calculate the optimal weight matrix\n",
      "C:\\Users\\mes7jw\\AppData\\Local\\Temp\\ipykernel_31344\\3580595035.py:19: FutureWarning: Calling a ufunc on non-aligned DataFrames (or DataFrame/Series combination). Currently, the indices are ignored and the result takes the index/columns of the first DataFrame. In the future , the DataFrames/Series will be aligned before applying the ufunc.\n",
      "Convert one of the arguments to a NumPy array (eg 'ufunc(df1, np.asarray(df2)') to keep the current behaviour, or align manually (eg 'df1, df2 = df1.align(df2)') before passing to the ufunc to obtain the future behaviour and silence this warning.\n",
      "  W_2 = np.linalg.inv((1/Endog.shape[0]) * np.matmul(np.matmul(Inst.T, np.diag(Resid_1**2)), Inst)) #we calculate the optimal weight matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Standard Error</th>\n",
       "      <th>T Statistic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>const</th>\n",
       "      <td>-7.106873</td>\n",
       "      <td>0.753486</td>\n",
       "      <td>-9.431994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Price_Norm</th>\n",
       "      <td>-2.570051</td>\n",
       "      <td>0.224098</td>\n",
       "      <td>-11.468417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weight_Norm</th>\n",
       "      <td>2.878105</td>\n",
       "      <td>0.829621</td>\n",
       "      <td>3.469179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HP_Norm</th>\n",
       "      <td>1.839356</td>\n",
       "      <td>0.561372</td>\n",
       "      <td>3.276539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AC</th>\n",
       "      <td>0.463188</td>\n",
       "      <td>0.236809</td>\n",
       "      <td>1.955953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogNest_Share</th>\n",
       "      <td>0.616129</td>\n",
       "      <td>0.072957</td>\n",
       "      <td>8.445140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Coefficient  Standard Error  T Statistic\n",
       "const            -7.106873        0.753486    -9.431994\n",
       "Price_Norm       -2.570051        0.224098   -11.468417\n",
       "Weight_Norm       2.878105        0.829621     3.469179\n",
       "HP_Norm           1.839356        0.561372     3.276539\n",
       "AC                0.463188        0.236809     1.955953\n",
       "LogNest_Share     0.616129        0.072957     8.445140"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_1992 = TwoStepGMM(Endog_1992,Exog_1992,Inst_1992)[2]\n",
    "se_1992 = TwoStepGMM(Endog_1992,Exog_1992,Inst_1992)[3]\n",
    "T_1992 = beta_1992/se_1992\n",
    "Res_1992 = pd.DataFrame({'Coefficient':beta_1992, 'Standard Error':se_1992, \"T Statistic\": T_1992}, index=['const', 'Price_Norm', 'Weight_Norm', 'HP_Norm', 'AC', 'LogNest_Share'])\n",
    "Res_1992"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to the multinomial logit model, the nested logit price coefficients are smaller, and vary slightly from year to year. This reduction in the coefficients stems in part from separating products into nests, and in part from removing intertemporal substitution as an option. The nest coefficients $\\sigma$ range from $0.54$ to $0.62$, suggesting that there is a moderate amount of correlation between products in the same nest.\n",
    "\n",
    "As before, the price coefficient is negative, and the characteristic coefficients are positive, suggesting that consumers prefer more powerful cars with air conditioning, and dislike higher prices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b). We can estimate a random-coefficient model using only one year of this dataset because we can leverage variation in product characteristics to estimate the parameters.\n",
    "\n",
    "(c). The elasticities are a little trickier to calculate in the nested logit. Following Miller's notes on the nested logit http://www.nathanhmiller.org/nlnotes.pdf, we have three possible forms:\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial s_j}{\\partial p_j} &= \\frac{-\\alpha}{1-\\sigma}s_j(1-\\sigma \\bar{s}_{j|g} - (1-\\sigma ) s_j)\\\\\n",
    "\\frac{\\partial s_j}{\\partial p_k} &= \\alpha s_k\\left( s_j + \\frac{\\sigma}{1-\\sigma} \\bar{s}_{j|g} \\right) \\text{ if } j,k \\in g\\\\\n",
    "\\frac{\\partial s_j}{\\partial p_k} &= \\alpha s_k s_j \\text{ if } j\\in g \\text{ and } k \\notin g\n",
    "\\end{align*}\n",
    "\n",
    "So that \n",
    "\\begin{align*}\n",
    "\\epsilon_j &= \\frac{-\\alpha}{1-\\sigma}p_j(1-\\sigma \\bar{s}_{j|g} - (1-\\sigma ) s_j)\\\\\n",
    "\\epsilon_{j,k} &= \\alpha \\frac{s_kp_k}{s_j}\\left( s_j + \\frac{\\sigma}{1-\\sigma} \\bar{s}_{j|g} \\right) \\text{ if } j,k \\in g\\\\\n",
    "\\epsilon_{j,k} &= \\alpha s_k p_k \\text{ if } j\\in g \\text{ and } k \\notin g\n",
    "\\end{align*}\n",
    "\n",
    "Note that these formulations assume $\\alpha >0$. When operationalizing, the sign of the price coefficient , $\\alpha$, is negative, so we need to flip the sign of the elasticities.\n",
    "\n",
    "For computing the elasticites, we use the results from the nonlinear GMM estimator, rather than the linear GMM estimator in Statsmodels. The nonlinear price coefficients are more consistent across years compared to the statsmodels results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.073890</td>\n",
       "      <td>0.006433</td>\n",
       "      <td>0.003633</td>\n",
       "      <td>0.141169</td>\n",
       "      <td>0.139149</td>\n",
       "      <td>0.004275</td>\n",
       "      <td>0.111580</td>\n",
       "      <td>0.004305</td>\n",
       "      <td>0.003317</td>\n",
       "      <td>0.098838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.008234</td>\n",
       "      <td>-4.227703</td>\n",
       "      <td>0.209781</td>\n",
       "      <td>0.003475</td>\n",
       "      <td>0.005357</td>\n",
       "      <td>0.197024</td>\n",
       "      <td>0.003243</td>\n",
       "      <td>0.155165</td>\n",
       "      <td>0.153034</td>\n",
       "      <td>0.003463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.008234</td>\n",
       "      <td>0.133487</td>\n",
       "      <td>-2.542015</td>\n",
       "      <td>0.003475</td>\n",
       "      <td>0.005357</td>\n",
       "      <td>0.118105</td>\n",
       "      <td>0.003243</td>\n",
       "      <td>0.093013</td>\n",
       "      <td>0.091735</td>\n",
       "      <td>0.003463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.124382</td>\n",
       "      <td>0.006433</td>\n",
       "      <td>0.003633</td>\n",
       "      <td>-2.522532</td>\n",
       "      <td>0.084852</td>\n",
       "      <td>0.004275</td>\n",
       "      <td>0.068041</td>\n",
       "      <td>0.004305</td>\n",
       "      <td>0.003317</td>\n",
       "      <td>0.060271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.194539</td>\n",
       "      <td>0.006433</td>\n",
       "      <td>0.003633</td>\n",
       "      <td>0.134639</td>\n",
       "      <td>-3.947278</td>\n",
       "      <td>0.004275</td>\n",
       "      <td>0.106419</td>\n",
       "      <td>0.004305</td>\n",
       "      <td>0.003317</td>\n",
       "      <td>0.094266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.008234</td>\n",
       "      <td>0.167277</td>\n",
       "      <td>0.157585</td>\n",
       "      <td>0.003475</td>\n",
       "      <td>0.005357</td>\n",
       "      <td>-3.195069</td>\n",
       "      <td>0.003243</td>\n",
       "      <td>0.116558</td>\n",
       "      <td>0.114957</td>\n",
       "      <td>0.003463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.146861</td>\n",
       "      <td>0.006433</td>\n",
       "      <td>0.003633</td>\n",
       "      <td>0.101642</td>\n",
       "      <td>0.100187</td>\n",
       "      <td>0.004275</td>\n",
       "      <td>-2.999724</td>\n",
       "      <td>0.004305</td>\n",
       "      <td>0.003317</td>\n",
       "      <td>0.071163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.008234</td>\n",
       "      <td>0.213875</td>\n",
       "      <td>0.201483</td>\n",
       "      <td>0.003475</td>\n",
       "      <td>0.005357</td>\n",
       "      <td>0.189230</td>\n",
       "      <td>0.003243</td>\n",
       "      <td>-4.125316</td>\n",
       "      <td>0.146980</td>\n",
       "      <td>0.003463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.008234</td>\n",
       "      <td>0.167065</td>\n",
       "      <td>0.157386</td>\n",
       "      <td>0.003475</td>\n",
       "      <td>0.005357</td>\n",
       "      <td>0.147815</td>\n",
       "      <td>0.003243</td>\n",
       "      <td>0.116410</td>\n",
       "      <td>-3.224034</td>\n",
       "      <td>0.003463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.177012</td>\n",
       "      <td>0.006433</td>\n",
       "      <td>0.003633</td>\n",
       "      <td>0.122509</td>\n",
       "      <td>0.120756</td>\n",
       "      <td>0.004275</td>\n",
       "      <td>0.096832</td>\n",
       "      <td>0.004305</td>\n",
       "      <td>0.003317</td>\n",
       "      <td>-3.626637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -4.073890  0.006433  0.003633  0.141169  0.139149  0.004275  0.111580   \n",
       "1  0.008234 -4.227703  0.209781  0.003475  0.005357  0.197024  0.003243   \n",
       "2  0.008234  0.133487 -2.542015  0.003475  0.005357  0.118105  0.003243   \n",
       "3  0.124382  0.006433  0.003633 -2.522532  0.084852  0.004275  0.068041   \n",
       "4  0.194539  0.006433  0.003633  0.134639 -3.947278  0.004275  0.106419   \n",
       "5  0.008234  0.167277  0.157585  0.003475  0.005357 -3.195069  0.003243   \n",
       "6  0.146861  0.006433  0.003633  0.101642  0.100187  0.004275 -2.999724   \n",
       "7  0.008234  0.213875  0.201483  0.003475  0.005357  0.189230  0.003243   \n",
       "8  0.008234  0.167065  0.157386  0.003475  0.005357  0.147815  0.003243   \n",
       "9  0.177012  0.006433  0.003633  0.122509  0.120756  0.004275  0.096832   \n",
       "\n",
       "          7         8         9  \n",
       "0  0.004305  0.003317  0.098838  \n",
       "1  0.155165  0.153034  0.003463  \n",
       "2  0.093013  0.091735  0.003463  \n",
       "3  0.004305  0.003317  0.060271  \n",
       "4  0.004305  0.003317  0.094266  \n",
       "5  0.116558  0.114957  0.003463  \n",
       "6  0.004305  0.003317  0.071163  \n",
       "7 -4.125316  0.146980  0.003463  \n",
       "8  0.116410 -3.224034  0.003463  \n",
       "9  0.004305  0.003317 -3.626637  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sort the 1990 data by quantity\n",
    "CarDataNL_1990 = CarDataNL_1990.sort_values(by=['Quantity'], ascending=False)\n",
    "#create a 10x10 matrix of zeros\n",
    "Elast_NL_1990 = np.zeros((10,10))\n",
    "#On the diagonal, we calculate the price elasticity of demand for each observation\n",
    "for i in range(10):\n",
    "    Elast_NL_1990[i,i] = beta_1990[1]/(1-beta_1990[5]) * CarDataNL_1990['Price_Norm'].iloc[i]*(1- beta_1990[5]*CarDataNL_1990['Nest_Share'].iloc[i] - (1-beta_1990[5])*CarDataNL_1990['Market_Share'].iloc[i])\n",
    "#On the off-diagonal, we calculate the cross-price elasticity of demand for each observation\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        if i != j:\n",
    "            if CarDataNL_1990['Nests'].iloc[i] == CarDataNL_1990['Nests'].iloc[j]:\n",
    "                Elast_NL_1990[i,j] = -beta_1990[1]* (CarDataNL_1990['Market_Share'].iloc[j]*CarDataNL_1990['Price_Norm'].iloc[i]/CarDataNL_1990['Market_Share'].iloc[i])*(CarDataNL_1990['Market_Share'].iloc[i] + (beta_1990[5]/(1-beta_1990[5]))*CarDataNL_1990['Nest_Share'].iloc[i])\n",
    "            else:\n",
    "                Elast_NL_1990[i,j] = -beta_1990[1]* CarDataNL_1990['Market_Share'].iloc[j]*CarDataNL_1990['Price_Norm'].iloc[j]\n",
    "            \n",
    "#print the matrix as a table\n",
    "pd.DataFrame(Elast_NL_1990)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.630980</td>\n",
       "      <td>0.005323</td>\n",
       "      <td>0.003420</td>\n",
       "      <td>0.127339</td>\n",
       "      <td>0.125532</td>\n",
       "      <td>0.003363</td>\n",
       "      <td>0.100616</td>\n",
       "      <td>0.004126</td>\n",
       "      <td>0.002849</td>\n",
       "      <td>0.089143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.007173</td>\n",
       "      <td>-3.576953</td>\n",
       "      <td>0.184692</td>\n",
       "      <td>0.002706</td>\n",
       "      <td>0.005480</td>\n",
       "      <td>0.173563</td>\n",
       "      <td>0.003073</td>\n",
       "      <td>0.136710</td>\n",
       "      <td>0.134771</td>\n",
       "      <td>0.003114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.007173</td>\n",
       "      <td>0.133596</td>\n",
       "      <td>-2.446244</td>\n",
       "      <td>0.002706</td>\n",
       "      <td>0.005480</td>\n",
       "      <td>0.118325</td>\n",
       "      <td>0.003073</td>\n",
       "      <td>0.093201</td>\n",
       "      <td>0.091879</td>\n",
       "      <td>0.003114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.100361</td>\n",
       "      <td>0.005323</td>\n",
       "      <td>0.003420</td>\n",
       "      <td>-2.010913</td>\n",
       "      <td>0.068453</td>\n",
       "      <td>0.003363</td>\n",
       "      <td>0.054866</td>\n",
       "      <td>0.004126</td>\n",
       "      <td>0.002849</td>\n",
       "      <td>0.048610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.206118</td>\n",
       "      <td>0.005323</td>\n",
       "      <td>0.003420</td>\n",
       "      <td>0.142611</td>\n",
       "      <td>-4.131989</td>\n",
       "      <td>0.003363</td>\n",
       "      <td>0.112683</td>\n",
       "      <td>0.004126</td>\n",
       "      <td>0.002849</td>\n",
       "      <td>0.099834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.007173</td>\n",
       "      <td>0.139798</td>\n",
       "      <td>0.131758</td>\n",
       "      <td>0.002706</td>\n",
       "      <td>0.005480</td>\n",
       "      <td>-2.567754</td>\n",
       "      <td>0.003073</td>\n",
       "      <td>0.097528</td>\n",
       "      <td>0.096145</td>\n",
       "      <td>0.003114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.144234</td>\n",
       "      <td>0.005323</td>\n",
       "      <td>0.003420</td>\n",
       "      <td>0.099794</td>\n",
       "      <td>0.098379</td>\n",
       "      <td>0.003363</td>\n",
       "      <td>-2.910947</td>\n",
       "      <td>0.004126</td>\n",
       "      <td>0.002849</td>\n",
       "      <td>0.069860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.007173</td>\n",
       "      <td>0.217703</td>\n",
       "      <td>0.205183</td>\n",
       "      <td>0.002706</td>\n",
       "      <td>0.005480</td>\n",
       "      <td>0.192819</td>\n",
       "      <td>0.003073</td>\n",
       "      <td>-4.039622</td>\n",
       "      <td>0.149723</td>\n",
       "      <td>0.003114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.007173</td>\n",
       "      <td>0.152513</td>\n",
       "      <td>0.143742</td>\n",
       "      <td>0.002706</td>\n",
       "      <td>0.005480</td>\n",
       "      <td>0.135080</td>\n",
       "      <td>0.003073</td>\n",
       "      <td>0.106399</td>\n",
       "      <td>-2.831486</td>\n",
       "      <td>0.003114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.164943</td>\n",
       "      <td>0.005323</td>\n",
       "      <td>0.003420</td>\n",
       "      <td>0.114122</td>\n",
       "      <td>0.112504</td>\n",
       "      <td>0.003363</td>\n",
       "      <td>0.090173</td>\n",
       "      <td>0.004126</td>\n",
       "      <td>0.002849</td>\n",
       "      <td>-3.339176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -3.630980  0.005323  0.003420  0.127339  0.125532  0.003363  0.100616   \n",
       "1  0.007173 -3.576953  0.184692  0.002706  0.005480  0.173563  0.003073   \n",
       "2  0.007173  0.133596 -2.446244  0.002706  0.005480  0.118325  0.003073   \n",
       "3  0.100361  0.005323  0.003420 -2.010913  0.068453  0.003363  0.054866   \n",
       "4  0.206118  0.005323  0.003420  0.142611 -4.131989  0.003363  0.112683   \n",
       "5  0.007173  0.139798  0.131758  0.002706  0.005480 -2.567754  0.003073   \n",
       "6  0.144234  0.005323  0.003420  0.099794  0.098379  0.003363 -2.910947   \n",
       "7  0.007173  0.217703  0.205183  0.002706  0.005480  0.192819  0.003073   \n",
       "8  0.007173  0.152513  0.143742  0.002706  0.005480  0.135080  0.003073   \n",
       "9  0.164943  0.005323  0.003420  0.114122  0.112504  0.003363  0.090173   \n",
       "\n",
       "          7         8         9  \n",
       "0  0.004126  0.002849  0.089143  \n",
       "1  0.136710  0.134771  0.003114  \n",
       "2  0.093201  0.091879  0.003114  \n",
       "3  0.004126  0.002849  0.048610  \n",
       "4  0.004126  0.002849  0.099834  \n",
       "5  0.097528  0.096145  0.003114  \n",
       "6  0.004126  0.002849  0.069860  \n",
       "7 -4.039622  0.149723  0.003114  \n",
       "8  0.106399 -2.831486  0.003114  \n",
       "9  0.004126  0.002849 -3.339176  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#repeat for 1991\n",
    "CarDataNL_1991 = CarDataNL_1991.sort_values(by=['Quantity'], ascending=False)\n",
    "Elast_NL_1991 = np.zeros((10,10))\n",
    "\n",
    "for i in range(10):\n",
    "    Elast_NL_1991[i,i] = beta_1991[1]/(1-beta_1991[5]) * CarDataNL_1991['Price_Norm'].iloc[i]*(1- beta_1991[5]*CarDataNL_1991['Nest_Share'].iloc[i] - (1-beta_1991[5])*CarDataNL_1991['Market_Share'].iloc[i])\n",
    "\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        if i != j:\n",
    "            if CarDataNL_1991['Nests'].iloc[i] == CarDataNL_1991['Nests'].iloc[j]:\n",
    "                Elast_NL_1991[i,j] = -beta_1991[1]* (CarDataNL_1991['Market_Share'].iloc[j]*CarDataNL_1991['Price_Norm'].iloc[i]/CarDataNL_1991['Market_Share'].iloc[i])*(CarDataNL_1991['Market_Share'].iloc[i] + (beta_1991[5]/(1-beta_1991[5]))*CarDataNL_1991['Nest_Share'].iloc[i])\n",
    "            else:\n",
    "                Elast_NL_1991[i,j] = -beta_1991[1]* CarDataNL_1991['Market_Share'].iloc[j]*CarDataNL_1991['Price_Norm'].iloc[j]\n",
    "\n",
    "pd.DataFrame(Elast_NL_1991)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.316308</td>\n",
       "      <td>0.175604</td>\n",
       "      <td>0.004355</td>\n",
       "      <td>0.005451</td>\n",
       "      <td>0.003243</td>\n",
       "      <td>0.144169</td>\n",
       "      <td>0.138642</td>\n",
       "      <td>0.004689</td>\n",
       "      <td>0.115334</td>\n",
       "      <td>0.003013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.111160</td>\n",
       "      <td>-2.288738</td>\n",
       "      <td>0.004355</td>\n",
       "      <td>0.005451</td>\n",
       "      <td>0.003243</td>\n",
       "      <td>0.075818</td>\n",
       "      <td>0.072911</td>\n",
       "      <td>0.004689</td>\n",
       "      <td>0.060654</td>\n",
       "      <td>0.003013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.007615</td>\n",
       "      <td>0.003327</td>\n",
       "      <td>-3.068701</td>\n",
       "      <td>0.167941</td>\n",
       "      <td>0.158129</td>\n",
       "      <td>0.005484</td>\n",
       "      <td>0.003742</td>\n",
       "      <td>0.140551</td>\n",
       "      <td>0.010389</td>\n",
       "      <td>0.115380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.007615</td>\n",
       "      <td>0.003327</td>\n",
       "      <td>0.237169</td>\n",
       "      <td>-4.093788</td>\n",
       "      <td>0.210236</td>\n",
       "      <td>0.005484</td>\n",
       "      <td>0.003742</td>\n",
       "      <td>0.186865</td>\n",
       "      <td>0.010389</td>\n",
       "      <td>0.153400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.007615</td>\n",
       "      <td>0.003327</td>\n",
       "      <td>0.149852</td>\n",
       "      <td>0.141078</td>\n",
       "      <td>-2.594852</td>\n",
       "      <td>0.005484</td>\n",
       "      <td>0.003742</td>\n",
       "      <td>0.118069</td>\n",
       "      <td>0.010389</td>\n",
       "      <td>0.096924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.223172</td>\n",
       "      <td>0.185406</td>\n",
       "      <td>0.004355</td>\n",
       "      <td>0.005451</td>\n",
       "      <td>0.003243</td>\n",
       "      <td>-4.628201</td>\n",
       "      <td>0.146381</td>\n",
       "      <td>0.004689</td>\n",
       "      <td>0.121772</td>\n",
       "      <td>0.003013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.158387</td>\n",
       "      <td>0.131584</td>\n",
       "      <td>0.004355</td>\n",
       "      <td>0.005451</td>\n",
       "      <td>0.003243</td>\n",
       "      <td>0.108029</td>\n",
       "      <td>-3.288806</td>\n",
       "      <td>0.004689</td>\n",
       "      <td>0.086422</td>\n",
       "      <td>0.003013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.007615</td>\n",
       "      <td>0.003327</td>\n",
       "      <td>0.243784</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.216099</td>\n",
       "      <td>0.005484</td>\n",
       "      <td>0.003742</td>\n",
       "      <td>-4.245390</td>\n",
       "      <td>0.010389</td>\n",
       "      <td>0.157678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.528519</td>\n",
       "      <td>0.439080</td>\n",
       "      <td>0.004355</td>\n",
       "      <td>0.005451</td>\n",
       "      <td>0.003243</td>\n",
       "      <td>0.360481</td>\n",
       "      <td>0.346660</td>\n",
       "      <td>0.004689</td>\n",
       "      <td>-11.032648</td>\n",
       "      <td>0.003013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.007615</td>\n",
       "      <td>0.003327</td>\n",
       "      <td>0.190814</td>\n",
       "      <td>0.179641</td>\n",
       "      <td>0.169145</td>\n",
       "      <td>0.005484</td>\n",
       "      <td>0.003742</td>\n",
       "      <td>0.150342</td>\n",
       "      <td>0.010389</td>\n",
       "      <td>-3.349873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -4.316308  0.175604  0.004355  0.005451  0.003243  0.144169  0.138642   \n",
       "1  0.111160 -2.288738  0.004355  0.005451  0.003243  0.075818  0.072911   \n",
       "2  0.007615  0.003327 -3.068701  0.167941  0.158129  0.005484  0.003742   \n",
       "3  0.007615  0.003327  0.237169 -4.093788  0.210236  0.005484  0.003742   \n",
       "4  0.007615  0.003327  0.149852  0.141078 -2.594852  0.005484  0.003742   \n",
       "5  0.223172  0.185406  0.004355  0.005451  0.003243 -4.628201  0.146381   \n",
       "6  0.158387  0.131584  0.004355  0.005451  0.003243  0.108029 -3.288806   \n",
       "7  0.007615  0.003327  0.243784  0.229508  0.216099  0.005484  0.003742   \n",
       "8  0.528519  0.439080  0.004355  0.005451  0.003243  0.360481  0.346660   \n",
       "9  0.007615  0.003327  0.190814  0.179641  0.169145  0.005484  0.003742   \n",
       "\n",
       "          7          8         9  \n",
       "0  0.004689   0.115334  0.003013  \n",
       "1  0.004689   0.060654  0.003013  \n",
       "2  0.140551   0.010389  0.115380  \n",
       "3  0.186865   0.010389  0.153400  \n",
       "4  0.118069   0.010389  0.096924  \n",
       "5  0.004689   0.121772  0.003013  \n",
       "6  0.004689   0.086422  0.003013  \n",
       "7 -4.245390   0.010389  0.157678  \n",
       "8  0.004689 -11.032648  0.003013  \n",
       "9  0.150342   0.010389 -3.349873  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#repeat the above for 1992\n",
    "CarDataNL_1992 = CarDataNL_1992.sort_values(by=['Quantity'], ascending=False)\n",
    "Elast_NL_1992 = np.zeros((10,10))\n",
    "\n",
    "for i in range(10):\n",
    "    Elast_NL_1992[i,i] = beta_1992[1]/(1-beta_1992[5]) * CarDataNL_1992['Price_Norm'].iloc[i]*(1- beta_1992[5]*CarDataNL_1992['Nest_Share'].iloc[i] - (1-beta_1992[5])*CarDataNL_1992['Market_Share'].iloc[i])\n",
    "\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        if i != j:\n",
    "            if CarDataNL_1992['Nests'].iloc[i] == CarDataNL_1992['Nests'].iloc[j]:\n",
    "                Elast_NL_1992[i,j] = -beta_1992[1]* (CarDataNL_1992['Market_Share'].iloc[j]*CarDataNL_1992['Price_Norm'].iloc[i]/CarDataNL_1992['Market_Share'].iloc[i])*(CarDataNL_1992['Market_Share'].iloc[i] + (beta_1992[5]/(1-beta_1992[5]))*CarDataNL_1992['Nest_Share'].iloc[i])\n",
    "            else:\n",
    "                Elast_NL_1992[i,j] = -beta_1992[1]* CarDataNL_1992['Market_Share'].iloc[j]*CarDataNL_1992['Price_Norm'].iloc[j]\n",
    "\n",
    "pd.DataFrame(Elast_NL_1992)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) If we pool all three years' worth of data to estimate nested-logit, we are implicitly assuming that the market size can be explained by one of the two scenarios. One, the market size stays the same (100 million) and a given household can choose between cars of the same make/model that are released in different years, as well as cars of different makes/models that are released in the same year; this scenario captures intertemporal substitution of cars of the same make/model. The data assigns the same car model in different years to the same nest, imposing that consumers have \n",
    "the same taste for car models across different years, and the same substitution pattern of the same car model in different years.\n",
    "Two, the market size increases to 300 million; this scenario assumes that 100 million new households enter the market each year and each household can only substitute between cars of different makes/models that are released in the same year. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8. (a) The Multinomial Probit model is flexible, but there is a dimensionality issue because there are more than $J=5$ products in this market, which means there are potentially $J^2$ parameters to estimate; we will need a lot of computing power to simulate an integral of dimension $J$, which makes the estimation less feasible. The nested logit model is more appropriate in this setting because there are natural nests in the automobile market, and it is reasonable to assume that goods across nests have zero taste correlation. For example, if I am a consumer who wants to buy a truck, it is likely that I am only choosing a product from the nest of trucks and not from the nest of sports convertible.\n",
    "\n",
    "(b) The Pure Characteristics model is well-suited in a market where quality (vertical characteristic) is dominant. The automobile market is horizontally differentiated in many dimensions, so the nested logit model, or a random coefficient logit model is more suited to model this setting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyBLP Tutorial\n",
    "\n",
    "We begin by importing the package and reading in the data (Note: Make sure to import the packages in the first python cell of the notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyblp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-c6833d481fc5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpyblp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpyblp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdigits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mproduct_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpyblp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNEVO_PRODUCTS_LOCATION\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mproduct_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyblp'"
     ]
    }
   ],
   "source": [
    "import pyblp\n",
    "pyblp.options.digits = 2\n",
    "\n",
    "product_data = pd.read_csv(pyblp.data.NEVO_PRODUCTS_LOCATION)\n",
    "product_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we specify the formulations of product characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(prices + Absorb[C(product_ids)], 1 + prices + sugar + mushy)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1_formulation = pyblp.Formulation('0 + prices', absorb='C(product_ids)') #these are the linear characteristics for the demand side\n",
    "X2_formulation = pyblp.Formulation('1 + prices + sugar + mushy') #these are the nonlinear characteristics for the demand side\n",
    "product_formulations = (X1_formulation, X2_formulation) #we combine the two formulations into one tuple\n",
    "product_formulations #we print the tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we define an integration method for simulating market shares. Here we use Monte Carlo integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Configured to construct nodes and weights with Monte Carlo simulation with options {seed: 0}."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_integration = pyblp.Integration('monte_carlo', size=50, specification_options={'seed': 0})\n",
    "mc_integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having defined our product formulation and integration method, we can now combine these into the problem class that PyBLP solves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing the problem ...\n",
      "Absorbing demand-side fixed effects ...\n",
      "Initialized the problem after 00:00:00.\n",
      "\n",
      "Dimensions:\n",
      "============================================\n",
      " T    N     F    I     K1    K2    MD    ED \n",
      "---  ----  ---  ----  ----  ----  ----  ----\n",
      "94   2256   5   4700   1     4     20    1  \n",
      "============================================\n",
      "\n",
      "Formulations:\n",
      "===========================================================\n",
      "       Column Indices:           0       1       2      3  \n",
      "-----------------------------  ------  ------  -----  -----\n",
      " X1: Linear Characteristics    prices                      \n",
      "X2: Nonlinear Characteristics    1     prices  sugar  mushy\n",
      "===========================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dimensions:\n",
       "============================================\n",
       " T    N     F    I     K1    K2    MD    ED \n",
       "---  ----  ---  ----  ----  ----  ----  ----\n",
       "94   2256   5   4700   1     4     20    1  \n",
       "============================================\n",
       "\n",
       "Formulations:\n",
       "===========================================================\n",
       "       Column Indices:           0       1       2      3  \n",
       "-----------------------------  ------  ------  -----  -----\n",
       " X1: Linear Characteristics    prices                      \n",
       "X2: Nonlinear Characteristics    1     prices  sugar  mushy\n",
       "==========================================================="
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_problem = pyblp.Problem(product_formulations, product_data, integration=mc_integration)\n",
    "mc_problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve the problem quickly, we use a solver with a loose tolerance and no support for parameter bounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Configured to optimize using the BFGS algorithm implemented in SciPy with analytic gradients and options {gtol: +1.0E-04}."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bfgs = pyblp.Optimization('bfgs', {'gtol': 1e-4})\n",
    "bfgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now estimate the model using the problem class and optimizer we just created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving the problem ...\n",
      "\n",
      "Nonlinear Coefficient Initial Values:\n",
      "=========================================================================================================\n",
      "Sigma:     1       prices    sugar     mushy    |  Sigma Squared:     1       prices    sugar     mushy  \n",
      "------  --------  --------  --------  --------  |  --------------  --------  --------  --------  --------\n",
      "  1     +1.0E+00                                |        1         +1.0E+00  +1.0E+00  +1.0E+00  +1.0E+00\n",
      "prices  +1.0E+00  +1.0E+00                      |      prices      +1.0E+00  +2.0E+00  +2.0E+00  +2.0E+00\n",
      "sugar   +1.0E+00  +1.0E+00  +1.0E+00            |      sugar       +1.0E+00  +2.0E+00  +3.0E+00  +3.0E+00\n",
      "mushy   +1.0E+00  +1.0E+00  +1.0E+00  +1.0E+00  |      mushy       +1.0E+00  +2.0E+00  +3.0E+00  +4.0E+00\n",
      "=========================================================================================================\n",
      "Starting optimization ...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GMM   Computation  Optimization   Objective   Fixed Point  Contraction  Clipped  Objective   Objective   Gradient                                                                                                    \n",
      "Step     Time       Iterations   Evaluations  Iterations   Evaluations  Shares     Value    Improvement    Norm                                                  Theta                                               \n",
      "----  -----------  ------------  -----------  -----------  -----------  -------  ---------  -----------  --------  --------------------------------------------------------------------------------------------------\n",
      " 1     00:00:01         0             1          2898         8803         0     +7.5E+03                +7.3E+03  +1.0E+00, +1.0E+00, +1.0E+00, +1.0E+00, +1.0E+00, +1.0E+00, +1.0E+00, +1.0E+00, +1.0E+00, +1.0E+00\n",
      " 1     00:00:01         0             2          1917         5860         0     +2.1E+03    +5.4E+03    +2.3E+03  +9.1E-01, +9.9E-01, +9.9E-01, +1.2E-01, +7.3E-01, +6.0E-01, +9.5E-01, +9.9E-01, +9.7E-01, +1.0E+00\n",
      "\n",
      "At least one error was encountered. As long as the optimization routine does not get stuck at values of theta that give rise to errors, this is not necessarily a problem. If the errors persist or seem to be impacting the optimization results, consider setting an error punishment or following any of the other suggestions below:\n",
      "The fixed point computation of delta failed to converge. This problem can sometimes be mitigated by increasing the maximum number of fixed point iterations, increasing the fixed point tolerance, choosing more reasonable initial parameter values, setting more conservative parameter or share bounds, or using different iteration or optimization configurations.\n",
      "\n",
      " 1     00:00:03         1             3          6102         18432        0     +1.9E+04                +9.8E+03  +7.0E-01, +9.8E-01, +9.3E-01, +6.1E-01, -2.7E+00, -1.4E+00, +7.6E-01, +8.8E-01, +8.5E-01, +1.0E+00\n",
      " 1     00:00:01         1             4          1143         3530         0     +7.8E+02    +1.3E+03    +2.2E+03  +8.7E-01, +9.9E-01, +9.8E-01, +2.2E-01, +5.6E-02, +2.0E-01, +9.2E-01, +9.7E-01, +9.5E-01, +1.0E+00\n",
      "\n",
      "At least one error was encountered. As long as the optimization routine does not get stuck at values of theta that give rise to errors, this is not necessarily a problem. If the errors persist or seem to be impacting the optimization results, consider setting an error punishment or following any of the other suggestions below:\n",
      "The fixed point computation of delta failed to converge. This problem can sometimes be mitigated by increasing the maximum number of fixed point iterations, increasing the fixed point tolerance, choosing more reasonable initial parameter values, setting more conservative parameter or share bounds, or using different iteration or optimization configurations.\n",
      "\n",
      " 1     00:00:11         2             5          26059        78294        0     +1.2E+05                +2.2E+04  -2.8E-01, +8.6E-01, +1.1E+00, +2.1E+00, +3.7E+00, -7.1E+00, +8.6E-01, -1.3E+00, +8.6E-01, -6.3E-01\n",
      " 1     00:00:01         2             6          1130         3472         0     +7.7E+02    +9.3E+00    +2.3E+03  +8.5E-01, +9.9E-01, +9.8E-01, +2.4E-01, +9.5E-02, +1.2E-01, +9.1E-01, +9.5E-01, +9.5E-01, +1.0E+00\n",
      " 1     00:00:01         3             7          1106         3406         0     +7.5E+02    +1.8E+01    +2.2E+03  +7.8E-01, +9.8E-01, +9.8E-01, +2.4E-01, +9.7E-02, +1.2E-01, +9.1E-01, +8.3E-01, +9.5E-01, +9.2E-01\n",
      " 1     00:00:01         3             8          1050         3244         0     +6.8E+02    +6.3E+01    +2.1E+03  +4.9E-01, +9.4E-01, +9.9E-01, +2.6E-01, +1.0E-01, +1.2E-01, +8.8E-01, +3.4E-01, +9.6E-01, +5.8E-01\n",
      " 1     00:00:01         4             9          1132         3494         0     +6.9E+02                +1.9E+03  -9.3E-01, +4.6E-01, +1.6E+00, +3.9E-01, +2.1E-01, +2.1E-01, -1.2E-01, +3.9E-01, -1.1E+00, +2.8E-01\n",
      " 1     00:00:01         4            10          1043         3203         0     +6.4E+02    +4.3E+01    +1.9E+03  -2.0E-01, +7.0E-01, +1.3E+00, +3.2E-01, +1.6E-01, +1.6E-01, +3.9E-01, +3.6E-01, -3.1E-02, +4.3E-01\n",
      " 1     00:00:01         5            11           973         3009         0     +5.6E+02    +7.7E+01    +1.7E+03  +1.1E-01, +3.7E-01, +1.9E+00, +2.9E-01, +1.3E-01, +1.7E-01, +1.9E-01, -6.9E-02, -4.8E-01, +4.9E-01\n",
      " 1     00:00:01         6            12           910         2814         0     +4.4E+02    +1.2E+02    +1.4E+03  -4.3E-02, -3.5E-01, +3.1E+00, +2.7E-01, +9.6E-02, +1.5E-01, -5.3E-01, -3.6E-01, -1.2E-01, +6.8E-01\n",
      " 1     00:00:01         7            13           822         2551         0     +3.1E+02    +1.3E+02    +9.3E+02  -2.2E-01, -1.8E+00, +5.4E+00, +1.7E-01, -1.2E-01, +6.2E-02, +4.5E-01, +7.3E-01, +3.9E-01, -1.3E+00\n",
      " 1     00:00:01         8            14          1169         3596         0     +5.7E+02                +9.2E+02  -2.8E+00, -4.0E+00, +8.7E+00, +1.9E-01, -3.2E-01, -5.1E-02, +5.4E+00, +4.6E-01, +4.4E-01, +8.9E-01\n",
      " 1     00:00:01         8            15           877         2731         0     +2.8E+02    +3.1E+01    +7.4E+02  -8.1E-01, -2.3E+00, +6.1E+00, +1.7E-01, -1.7E-01, +3.6E-02, +1.6E+00, +6.7E-01, +4.0E-01, -7.9E-01\n",
      " 1     00:00:00         9            16           791         2452         0     +2.3E+02    +5.2E+01    +5.5E+02  -5.4E-01, -2.9E+00, +7.5E+00, +1.4E-01, -1.7E-01, +2.8E-02, +1.0E+00, +3.8E-01, +2.2E-01, -5.4E-01\n",
      " 1     00:00:00         10           17           581         1800         0     +1.8E+02    +5.1E+01    +1.1E+02  +1.3E-01, -3.3E+00, +9.0E+00, +1.5E-02, -1.3E-01, +1.5E-02, +1.8E-01, +2.0E-01, +2.3E-01, +3.7E-01\n",
      " 1     00:00:00         11           18           708         2206         0     +1.8E+02    +1.1E+00    +1.2E+02  +1.0E-01, -3.6E+00, +1.1E+01, +4.0E-02, -1.6E-01, +4.0E-02, -3.1E-02, -6.9E-01, -2.5E-01, +6.1E-01\n",
      " 1     00:00:00         12           19           683         2138         0     +1.7E+02    +2.0E+00    +9.6E+01  +1.5E-01, -3.6E+00, +1.1E+01, +3.5E-02, -1.6E-01, +3.6E-02, -2.3E-02, -5.9E-01, -1.8E-01, +5.6E-01\n",
      " 1     00:00:00         13           20           642         2004         0     +1.7E+02    +2.5E+00    +2.1E+01  +2.7E-01, -3.7E+00, +1.0E+01, +2.2E-02, -1.4E-01, +3.1E-02, -4.3E-02, -4.2E-01, -2.6E-02, +4.6E-01\n",
      " 1     00:00:00         14           21           635         1969         0     +1.7E+02    +2.8E-01    +3.6E+00  +3.6E-01, -3.8E+00, +1.0E+01, +1.4E-02, -1.4E-01, +2.7E-02, -8.9E-02, -3.8E-01, +4.2E-02, +3.9E-01\n",
      " 1     00:00:00         15           22           631         1970         0     +1.7E+02    +6.8E-02    +4.5E+00  +4.1E-01, -3.9E+00, +1.0E+01, +1.2E-02, -1.4E-01, +2.7E-02, -1.4E-01, -4.1E-01, +6.1E-02, +3.8E-01\n",
      " 1     00:00:01         16           23           640         1998         0     +1.7E+02    +7.4E-02    +3.8E+00  +5.0E-01, -4.2E+00, +1.0E+01, +1.1E-02, -1.4E-01, +2.6E-02, -2.5E-01, -4.6E-01, +9.0E-02, +3.6E-01\n",
      " 1     00:00:01         17           24           641         1999         0     +1.7E+02    +2.4E-02    +1.9E+00  +5.3E-01, -4.4E+00, +1.1E+01, +1.3E-02, -1.4E-01, +2.6E-02, -2.9E-01, -4.8E-01, +9.6E-02, +3.6E-01\n",
      " 1     00:00:00         18           25           645         2013         0     +1.7E+02    +4.7E-02    +1.4E+00  +5.8E-01, -4.8E+00, +1.1E+01, +1.8E-02, -1.4E-01, +2.5E-02, -3.5E-01, -4.9E-01, +1.0E-01, +3.5E-01\n",
      " 1     00:00:00         18           26           657         2049         0     +1.7E+02    +9.5E-02    +1.4E+01  +7.8E-01, -6.4E+00, +1.1E+01, +3.4E-02, -1.4E-01, +2.4E-02, -5.9E-01, -5.5E-01, +1.3E-01, +3.4E-01\n",
      " 1     00:00:00         19           27           657         2049         0     +1.7E+02    +1.6E-01    +2.1E+01  +8.5E-01, -7.3E+00, +1.1E+01, +4.4E-02, -1.4E-01, +2.5E-02, -6.6E-01, -5.6E-01, +1.2E-01, +3.4E-01\n",
      " 1     00:00:00         19           28           672         2101         0     +1.7E+02    +1.2E-01    +6.0E+01  +1.1E+00, -1.1E+01, +1.0E+01, +8.3E-02, -1.3E-01, +2.6E-02, -9.4E-01, -6.1E-01, +7.6E-02, +3.2E-01\n",
      " 1     00:00:00         19           29           674         2103         0     +1.7E+02    +1.0E-01    +3.5E+01  +9.7E-01, -8.8E+00, +1.0E+01, +6.1E-02, -1.3E-01, +2.5E-02, -7.8E-01, -5.8E-01, +9.9E-02, +3.3E-01\n",
      " 1     00:00:01         20           30           657         2065         0     +1.7E+02    +3.8E-01    +6.7E+01  +1.1E+00, -1.1E+01, +9.6E+00, +9.0E-02, -1.2E-01, +2.8E-02, -8.8E-01, -5.8E-01, +2.5E-02, +3.3E-01\n",
      " 1     00:00:00         21           31           654         2043         0     +1.7E+02    +6.2E-01    +5.4E+01  +1.1E+00, -1.1E+01, +9.2E+00, +8.6E-02, -1.1E-01, +3.0E-02, -7.5E-01, -5.2E-01, -1.8E-02, +3.5E-01\n",
      " 1     00:00:00         22           32           639         1993         0     +1.7E+02    +8.5E-01    +1.8E+01  +1.2E+00, -1.2E+01, +8.4E+00, +8.3E-02, -1.0E-01, +3.4E-02, -7.2E-01, -4.8E-01, -7.2E-02, +3.4E-01\n",
      " 1     00:00:01         23           33           625         1959         0     +1.7E+02    +3.0E-01    +1.0E+01  +1.3E+00, -1.3E+01, +7.6E+00, +8.3E-02, -9.5E-02, +3.5E-02, -7.0E-01, -4.8E-01, -1.0E-01, +3.3E-01\n",
      " 1     00:00:00         24           34           626         1962         0     +1.7E+02    +8.7E-02    +5.6E+00  +1.4E+00, -1.4E+01, +7.3E+00, +8.4E-02, -9.0E-02, +3.5E-02, -7.0E-01, -5.0E-01, -8.7E-02, +3.3E-01\n",
      " 1     00:00:00         25           35           632         1968         0     +1.7E+02    +5.1E-02    +2.6E+00  +1.4E+00, -1.4E+01, +6.8E+00, +8.8E-02, -8.5E-02, +3.4E-02, -6.9E-01, -5.2E-01, -6.2E-02, +3.4E-01\n",
      " 1     00:00:01         26           36           623         1958         0     +1.7E+02    +6.9E-03    +4.7E+00  +1.3E+00, -1.4E+01, +6.8E+00, +8.6E-02, -8.5E-02, +3.2E-02, -6.7E-01, -5.2E-01, -2.9E-02, +3.4E-01\n",
      " 1     00:00:01         27           37           624         1959         0     +1.7E+02    +7.7E-03    +5.1E-01  +1.3E+00, -1.4E+01, +6.8E+00, +8.8E-02, -8.4E-02, +3.3E-02, -6.7E-01, -5.1E-01, -3.4E-02, +3.4E-01\n",
      " 1     00:00:00         28           38           625         1962         0     +1.7E+02    +3.4E-04    +1.4E-01  +1.3E+00, -1.4E+01, +6.8E+00, +8.8E-02, -8.5E-02, +3.3E-02, -6.7E-01, -5.1E-01, -3.6E-02, +3.4E-01\n",
      " 1     00:00:00         29           39           623         1961         0     +1.7E+02    +3.2E-05    +9.4E-02  +1.3E+00, -1.4E+01, +6.8E+00, +8.8E-02, -8.4E-02, +3.3E-02, -6.7E-01, -5.0E-01, -3.6E-02, +3.4E-01\n",
      " 1     00:00:01         30           40           624         1962         0     +1.7E+02    +6.1E-06    +3.6E-02  +1.3E+00, -1.4E+01, +6.7E+00, +8.8E-02, -8.4E-02, +3.3E-02, -6.7E-01, -5.0E-01, -3.6E-02, +3.4E-01\n",
      " 1     00:00:01         31           41           625         1962         0     +1.7E+02    +7.2E-07    +7.0E-03  +1.3E+00, -1.4E+01, +6.7E+00, +8.8E-02, -8.4E-02, +3.3E-02, -6.7E-01, -5.0E-01, -3.6E-02, +3.4E-01\n",
      " 1     00:00:00         32           42           624         1962         0     +1.7E+02    +5.9E-08    +1.8E-03  +1.3E+00, -1.4E+01, +6.7E+00, +8.8E-02, -8.4E-02, +3.3E-02, -6.7E-01, -5.0E-01, -3.6E-02, +3.4E-01\n",
      " 1     00:00:01         33           43           624         1962         0     +1.7E+02    +5.1E-09    +1.2E-03  +1.3E+00, -1.4E+01, +6.7E+00, +8.8E-02, -8.4E-02, +3.3E-02, -6.7E-01, -5.0E-01, -3.6E-02, +3.4E-01\n",
      " 1     00:00:01         34           44           624         1962         0     +1.7E+02    +4.2E-10    +3.1E-04  +1.3E+00, -1.4E+01, +6.7E+00, +8.8E-02, -8.4E-02, +3.3E-02, -6.7E-01, -5.0E-01, -3.6E-02, +3.4E-01\n",
      " 1     00:00:01         35           45           624         1962         0     +1.7E+02    +2.6E-11    +4.2E-05  +1.3E+00, -1.4E+01, +6.7E+00, +8.8E-02, -8.4E-02, +3.3E-02, -6.7E-01, -5.0E-01, -3.6E-02, +3.4E-01\n",
      "\n",
      "Optimization completed after 00:00:39.\n",
      "Computing the Hessian and and updating the weighting matrix ...\n",
      "Computed results after 00:00:11.\n",
      "\n",
      "Problem Results Summary:\n",
      "====================================================================================\n",
      "GMM   Objective  Gradient      Hessian         Hessian     Clipped  Weighting Matrix\n",
      "Step    Value      Norm    Min Eigenvalue  Max Eigenvalue  Shares   Condition Number\n",
      "----  ---------  --------  --------------  --------------  -------  ----------------\n",
      " 1    +1.7E+02   +4.2E-05     +1.2E-01        +7.4E+03        0         +6.9E+07    \n",
      "====================================================================================\n",
      "\n",
      "Starting optimization ...\n",
      "\n",
      "GMM   Computation  Optimization   Objective   Fixed Point  Contraction  Clipped  Objective   Objective   Gradient                                                                                                    \n",
      "Step     Time       Iterations   Evaluations  Iterations   Evaluations  Shares     Value    Improvement    Norm                                                  Theta                                               \n",
      "----  -----------  ------------  -----------  -----------  -----------  -------  ---------  -----------  --------  --------------------------------------------------------------------------------------------------\n",
      " 2     00:00:00         0             1            0           94          0     +1.5E+02                +4.9E+01  +1.3E+00, -1.4E+01, +6.7E+00, +8.8E-02, -8.4E-02, +3.3E-02, -6.7E-01, -5.0E-01, -3.6E-02, +3.4E-01\n",
      " 2     00:00:01         0             2          1774         5426         0     +1.7E+03                +2.8E+03  +1.3E+00, -1.4E+01, +6.8E+00, -5.7E-01, +6.4E-01, +2.7E-01, -6.6E-01, -5.0E-01, -2.0E-02, +3.9E-01\n",
      " 2     00:00:00         0             3           500         1572         0     +1.5E+02    +3.3E-01    +3.3E+01  +1.3E+00, -1.4E+01, +6.7E+00, +7.6E-02, -7.1E-02, +3.7E-02, -6.7E-01, -5.0E-01, -3.6E-02, +3.4E-01\n",
      " 2     00:00:00         1             4           564         1768         0     +1.6E+02                +1.6E+02  +1.3E+00, -1.4E+01, +6.7E+00, +1.0E-01, -4.3E-02, +6.1E-02, -6.6E-01, -5.1E-01, -3.5E-02, +3.6E-01\n",
      " 2     00:00:00         1             5           499         1575         0     +1.5E+02    +1.8E-02    +2.3E+01  +1.3E+00, -1.4E+01, +6.7E+00, +7.7E-02, -7.0E-02, +3.8E-02, -6.7E-01, -5.0E-01, -3.6E-02, +3.4E-01\n",
      " 2     00:00:00         2             6           503         1584         0     +1.5E+02    +3.4E-02    +2.5E+01  +1.3E+00, -1.4E+01, +6.7E+00, +7.7E-02, -6.9E-02, +3.8E-02, -6.7E-01, -5.1E-01, -3.6E-02, +3.5E-01\n",
      " 2     00:00:00         2             7           504         1580         0     +1.5E+02    +1.1E-01    +3.1E+01  +1.3E+00, -1.4E+01, +6.7E+00, +7.6E-02, -6.8E-02, +3.6E-02, -6.6E-01, -5.1E-01, -3.6E-02, +3.6E-01\n",
      " 2     00:00:00         3             8           502         1579         0     +1.5E+02    +2.3E-01    +2.4E+01  +1.4E+00, -1.4E+01, +6.7E+00, +7.2E-02, -7.0E-02, +3.9E-02, -6.4E-01, -5.2E-01, -3.5E-02, +3.8E-01\n",
      " 2     00:00:00         4             9           511         1610         0     +1.5E+02                +2.0E+01  +1.3E+00, -1.4E+01, +6.8E+00, +8.1E-02, -6.6E-02, +3.9E-02, -6.8E-01, -6.1E-01, -1.8E-02, +5.8E-01\n",
      " 2     00:00:00         4            10           499         1572         0     +1.5E+02    +7.6E-02    +2.2E+01  +1.3E+00, -1.4E+01, +6.8E+00, +7.5E-02, -6.8E-02, +3.9E-02, -6.5E-01, -5.5E-01, -3.0E-02, +4.5E-01\n",
      " 2     00:00:00         5            11           506         1584         0     +1.5E+02    +1.2E-01    +1.8E+01  +1.4E+00, -1.4E+01, +6.8E+00, +7.4E-02, -6.8E-02, +3.8E-02, -6.4E-01, -5.9E-01, -1.5E-02, +4.5E-01\n",
      " 2     00:00:00         6            12           499         1574         0     +1.5E+02    +1.7E-01    +8.6E+00  +1.4E+00, -1.4E+01, +6.9E+00, +7.2E-02, -7.3E-02, +3.7E-02, -6.3E-01, -5.5E-01, -1.1E-02, +4.8E-01\n",
      " 2     00:00:00         7            13           513         1603         0     +1.5E+02                +6.1E+00  +1.4E+00, -1.3E+01, +7.3E+00, +6.8E-02, -7.7E-02, +5.0E-02, -6.7E-01, -6.4E-01, -3.0E-01, +5.0E-01\n",
      " 2     00:00:00         7            14           504         1583         0     +1.5E+02    +4.1E-02    +5.2E+00  +1.4E+00, -1.4E+01, +7.0E+00, +7.1E-02, -7.4E-02, +4.0E-02, -6.4E-01, -5.7E-01, -7.8E-02, +4.9E-01\n",
      " 2     00:00:00         8            15           507         1589         0     +1.5E+02    +7.1E-02    +1.7E+00  +1.4E+00, -1.3E+01, +7.1E+00, +7.0E-02, -7.6E-02, +4.0E-02, -6.2E-01, -5.8E-01, -6.4E-02, +4.9E-01\n",
      " 2     00:00:00         9            16           518         1612         0     +1.5E+02    +2.8E-02    +4.4E+00  +1.4E+00, -1.3E+01, +7.4E+00, +6.7E-02, -8.0E-02, +3.6E-02, -7.0E-01, -6.3E-01, +1.5E-02, +4.9E-01\n",
      " 2     00:00:00         10           17           507         1597         0     +1.5E+02    +5.1E-02    +5.6E+00  +1.4E+00, -1.3E+01, +7.5E+00, +6.6E-02, -8.1E-02, +3.6E-02, -6.8E-01, -6.3E-01, +1.3E-02, +4.9E-01\n",
      " 2     00:00:00         11           18           521         1631         0     +1.5E+02    +8.4E-02    +5.6E+00  +1.4E+00, -1.3E+01, +7.8E+00, +6.5E-02, -8.4E-02, +3.7E-02, -6.4E-01, -6.3E-01, +1.0E-03, +4.9E-01\n",
      " 2     00:00:00         12           19           522         1648         0     +1.5E+02    +8.9E-02    +4.4E+00  +1.3E+00, -1.2E+01, +8.3E+00, +6.3E-02, -9.0E-02, +3.8E-02, -5.8E-01, -6.3E-01, -2.0E-02, +4.9E-01\n",
      " 2     00:00:00         13           20           521         1640         0     +1.5E+02    +2.0E-02    +2.5E+00  +1.2E+00, -1.2E+01, +8.4E+00, +6.2E-02, -9.1E-02, +3.8E-02, -5.8E-01, -6.3E-01, -2.4E-02, +4.9E-01\n",
      " 2     00:00:00         14           21           521         1640         0     +1.5E+02    +1.6E-02    +6.0E-01  +1.2E+00, -1.2E+01, +8.5E+00, +6.1E-02, -9.2E-02, +3.8E-02, -5.9E-01, -6.2E-01, -2.5E-02, +4.8E-01\n",
      " 2     00:00:00         15           22           528         1659         0     +1.5E+02    +2.1E-03    +5.8E-01  +1.2E+00, -1.1E+01, +8.5E+00, +6.1E-02, -9.2E-02, +3.8E-02, -5.9E-01, -6.2E-01, -2.4E-02, +4.8E-01\n",
      " 2     00:00:00         16           23           525         1649         0     +1.5E+02    +5.3E-04    +3.1E-01  +1.2E+00, -1.1E+01, +8.4E+00, +6.1E-02, -9.1E-02, +3.8E-02, -5.9E-01, -6.2E-01, -2.3E-02, +4.8E-01\n",
      " 2     00:00:00         17           24           528         1658         0     +1.5E+02    +1.2E-04    +8.9E-02  +1.2E+00, -1.1E+01, +8.4E+00, +6.1E-02, -9.1E-02, +3.8E-02, -5.9E-01, -6.2E-01, -2.2E-02, +4.8E-01\n",
      " 2     00:00:00         18           25           527         1656         0     +1.5E+02    +1.7E-05    +5.7E-03  +1.2E+00, -1.1E+01, +8.4E+00, +6.1E-02, -9.1E-02, +3.8E-02, -5.9E-01, -6.2E-01, -2.3E-02, +4.8E-01\n",
      " 2     00:00:00         19           26           526         1654         0     +1.5E+02    +6.6E-07    +3.6E-03  +1.2E+00, -1.1E+01, +8.4E+00, +6.1E-02, -9.1E-02, +3.8E-02, -5.9E-01, -6.2E-01, -2.3E-02, +4.8E-01\n",
      " 2     00:00:00         20           27           526         1652         0     +1.5E+02    +1.3E-08    +7.1E-04  +1.2E+00, -1.1E+01, +8.4E+00, +6.1E-02, -9.1E-02, +3.8E-02, -5.9E-01, -6.2E-01, -2.3E-02, +4.8E-01\n",
      " 2     00:00:00         21           28           526         1651         0     +1.5E+02    +1.5E-10    +8.7E-05  +1.2E+00, -1.1E+01, +8.4E+00, +6.1E-02, -9.1E-02, +3.8E-02, -5.9E-01, -6.2E-01, -2.3E-02, +4.8E-01\n",
      "\n",
      "Optimization completed after 00:00:13.\n",
      "Computing the Hessian and estimating standard errors ...\n",
      "Computed results after 00:00:09.\n",
      "\n",
      "Problem Results Summary:\n",
      "=======================================================================================================\n",
      "GMM   Objective  Gradient      Hessian         Hessian     Clipped  Weighting Matrix  Covariance Matrix\n",
      "Step    Value      Norm    Min Eigenvalue  Max Eigenvalue  Shares   Condition Number  Condition Number \n",
      "----  ---------  --------  --------------  --------------  -------  ----------------  -----------------\n",
      " 2    +1.5E+02   +8.7E-05     +8.5E-02        +6.5E+03        0         +5.2E+07          +8.3E+05     \n",
      "=======================================================================================================\n",
      "\n",
      "Cumulative Statistics:\n",
      "===========================================================================\n",
      "Computation  Optimizer  Optimization   Objective   Fixed Point  Contraction\n",
      "   Time      Converged   Iterations   Evaluations  Iterations   Evaluations\n",
      "-----------  ---------  ------------  -----------  -----------  -----------\n",
      " 00:01:12       Yes          58           75          83992       258145   \n",
      "===========================================================================\n",
      "\n",
      "Nonlinear Coefficient Estimates (Robust SEs in Parentheses):\n",
      "=========================================================================================================================\n",
      "Sigma:      1         prices      sugar       mushy     |  Sigma Squared:      1         prices      sugar       mushy   \n",
      "------  ----------  ----------  ----------  ----------  |  --------------  ----------  ----------  ----------  ----------\n",
      "  1      +1.2E+00                                       |        1          +1.5E+00    -1.4E+01    +7.3E-02    -7.1E-01 \n",
      "        (+3.0E+00)                                      |                  (+7.2E+00)  (+5.2E+01)  (+2.2E-01)  (+2.3E+00)\n",
      "                                                        |                                                                \n",
      "prices   -1.1E+01    +8.4E+00                           |      prices       -1.4E+01    +2.0E+02    -1.5E+00    +1.5E+00 \n",
      "        (+1.8E+01)  (+1.2E+01)                          |                  (+5.2E+01)  (+3.1E+02)  (+1.2E+00)  (+1.5E+01)\n",
      "                                                        |                                                                \n",
      "sugar    +6.1E-02    -9.1E-02    +3.8E-02               |      sugar        +7.3E-02    -1.5E+00    +1.3E-02    +2.0E-02 \n",
      "        (+2.5E-01)  (+2.3E-01)  (+8.3E-02)              |                  (+2.2E-01)  (+1.2E+00)  (+2.8E-02)  (+2.7E-01)\n",
      "                                                        |                                                                \n",
      "mushy    -5.9E-01    -6.2E-01    -2.3E-02    +4.8E-01   |      mushy        -7.1E-01    +1.5E+00    +2.0E-02    +9.6E-01 \n",
      "        (+2.1E+00)  (+1.5E+00)  (+2.5E+00)  (+1.3E+00)  |                  (+2.3E+00)  (+1.5E+01)  (+2.7E-01)  (+4.0E+00)\n",
      "=========================================================================================================================\n",
      "\n",
      "Beta Estimates (Robust SEs in Parentheses):\n",
      "==========\n",
      "  prices  \n",
      "----------\n",
      " -3.1E+01 \n",
      "(+6.0E+00)\n",
      "==========\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Problem Results Summary:\n",
       "=======================================================================================================\n",
       "GMM   Objective  Gradient      Hessian         Hessian     Clipped  Weighting Matrix  Covariance Matrix\n",
       "Step    Value      Norm    Min Eigenvalue  Max Eigenvalue  Shares   Condition Number  Condition Number \n",
       "----  ---------  --------  --------------  --------------  -------  ----------------  -----------------\n",
       " 2    +1.5E+02   +8.7E-05     +8.5E-02        +6.5E+03        0         +5.2E+07          +8.3E+05     \n",
       "=======================================================================================================\n",
       "\n",
       "Cumulative Statistics:\n",
       "===========================================================================\n",
       "Computation  Optimizer  Optimization   Objective   Fixed Point  Contraction\n",
       "   Time      Converged   Iterations   Evaluations  Iterations   Evaluations\n",
       "-----------  ---------  ------------  -----------  -----------  -----------\n",
       " 00:01:12       Yes          58           75          83992       258145   \n",
       "===========================================================================\n",
       "\n",
       "Nonlinear Coefficient Estimates (Robust SEs in Parentheses):\n",
       "=========================================================================================================================\n",
       "Sigma:      1         prices      sugar       mushy     |  Sigma Squared:      1         prices      sugar       mushy   \n",
       "------  ----------  ----------  ----------  ----------  |  --------------  ----------  ----------  ----------  ----------\n",
       "  1      +1.2E+00                                       |        1          +1.5E+00    -1.4E+01    +7.3E-02    -7.1E-01 \n",
       "        (+3.0E+00)                                      |                  (+7.2E+00)  (+5.2E+01)  (+2.2E-01)  (+2.3E+00)\n",
       "                                                        |                                                                \n",
       "prices   -1.1E+01    +8.4E+00                           |      prices       -1.4E+01    +2.0E+02    -1.5E+00    +1.5E+00 \n",
       "        (+1.8E+01)  (+1.2E+01)                          |                  (+5.2E+01)  (+3.1E+02)  (+1.2E+00)  (+1.5E+01)\n",
       "                                                        |                                                                \n",
       "sugar    +6.1E-02    -9.1E-02    +3.8E-02               |      sugar        +7.3E-02    -1.5E+00    +1.3E-02    +2.0E-02 \n",
       "        (+2.5E-01)  (+2.3E-01)  (+8.3E-02)              |                  (+2.2E-01)  (+1.2E+00)  (+2.8E-02)  (+2.7E-01)\n",
       "                                                        |                                                                \n",
       "mushy    -5.9E-01    -6.2E-01    -2.3E-02    +4.8E-01   |      mushy        -7.1E-01    +1.5E+00    +2.0E-02    +9.6E-01 \n",
       "        (+2.1E+00)  (+1.5E+00)  (+2.5E+00)  (+1.3E+00)  |                  (+2.3E+00)  (+1.5E+01)  (+2.7E-01)  (+4.0E+00)\n",
       "=========================================================================================================================\n",
       "\n",
       "Beta Estimates (Robust SEs in Parentheses):\n",
       "==========\n",
       "  prices  \n",
       "----------\n",
       " -3.1E+01 \n",
       "(+6.0E+00)\n",
       "=========="
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results1 = mc_problem.solve(sigma=np.ones((4, 4)), optimization=bfgs)\n",
    "results1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
